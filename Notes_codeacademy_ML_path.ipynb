{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Introduction\n",
    "\n",
    "What is Machine Learning?\n",
    "\n",
    "Machine learning is an umbrella term for a set of algorithms that analyze and find patterns from known historical information (“training data”) to make predictions on unknown/new information. \n",
    "“The field of study that gives computers the ability to learn without being explicitly programmed.”\n",
    "What goes into these algorithms?\n",
    "\n",
    "    Mathematics: Mathematical functions form the basis of the modeling process. Specifically, the fields of Probability, Linear Algebra and Calculus are crucial to building mathematical systems capable of modeling real-world data.\n",
    "      \n",
    "    Computer Science: Programming languages implement these mathematical models by translating them into a series of executable tasks that a computing machine can implement.  \n",
    "      \n",
    "    Statistics: Statistical inference and evaluation techniques are at the heart of making sure the model reflects the data as much as possible. They help us answer: How do we know our model works?\n",
    "\n",
    "The parameters in the mathematical models (mathematics) are “learned” by implementing them using programming (computer science) and upon evaluating their performance (statistics), they’re altered if unsatisfactory… And implemented and evaluated again to see if they perform better and so on and so forth.\n",
    "\n",
    "The machine learning process is thus not a one-and-done process. Rather, it’s iterative. Not unlike the way we humans learn! :) This capacity of machine learning to simulate human cognition makes it a subfield of Artificial Intelligence(AI).\n",
    "  \n",
    "\n",
    "\n",
    "### Machine Learning Engineering  \n",
    "\n",
    "Storing and accessing vast amounts of data requires robust hardware and pipelines. And running a machine learning algorithm requires lots of computing power and an infrastructure that allows for a seamless flow of data between the different steps of the algorithm. Here’s where the “engineering” in Machine Learning Engineering comes in!\n",
    "\n",
    "Machine Learning Engineering concerns itself with designing, building, maintaining and fine-tuning computational systems that can execute sophisticated machine learning algorithms on large amounts of data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning: Regression\n",
    "\n",
    "Machine learning can be branched out into the following categories:\n",
    "\n",
    "    **Supervised Learning**\n",
    "    **Unsupervised Learning**\n",
    "\n",
    "Supervised Learning is where the data is labeled and the program learns to predict the output from the input data. For instance, a supervised learning algorithm for credit card fraud detection would take as input a set of recorded transactions. For each transaction, the program would predict if it is fraudulent or not.\n",
    "\n",
    "Supervised learning problems can be further grouped into regression and classification problems.\n",
    "\n",
    "Regression:\n",
    "\n",
    "In regression problems, we are trying to predict a continuous-valued output. Examples are:\n",
    "\n",
    "    What is the housing price in New York?\n",
    "    What is the value of cryptocurrencies?\n",
    "\n",
    "Classification:\n",
    "\n",
    "In classification problems, we are trying to predict a discrete number of values. Examples are:\n",
    "\n",
    "    Is this a picture of a human or a picture of a cyborg?\n",
    "    Is this email spam?\n",
    "\n",
    "For a quick preview, here’s an example of a regression problem.\n",
    "\n",
    "A real estate company wants to analyze housing costs in Neo York. They built a linear regression model to predict rent prices from two variables: the square footage of each apartment and the number of burglaries in the apartment’s neighborhood during the past year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised Learning\n",
    "\n",
    "Unsupervised Learning is a type of machine learning where the program learns the inherent structure of the data based on unlabeled examples.\n",
    "\n",
    "Clustering is a common unsupervised machine learning approach that finds patterns and structures in unlabeled data by grouping them into clusters.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "    Social networks clustering topics in their news feed\n",
    "    Consumer sites clustering users for recommendations\n",
    "    Search engines to group similar objects in one cluster\n",
    "\n",
    "For a quick preview, here’s an example of unsupervised learning.\n",
    "\n",
    "A social media platform wants to separate their users into categories based on what kind of content they engage with. They have collected three pieces of data from a sample of users:\n",
    "\n",
    "    Number of hours per week spent reading posts\n",
    "    Number of hours per week spent watching videos\n",
    "    Number of hours per week spent in virtual reality\n",
    "\n",
    "The company is using an algorithm called k-means clustering to sort users into three different groups.  \n",
    "  \n",
    "  \n",
    "Supervised Learning: data is labeled and the program learns to predict the output from the input data  \n",
    "Unsupervised Learning: data is unlabeled and the program learns to recognize the inherent structure in the input data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipelines  \n",
    "\n",
    "### Column Transformer\n",
    "\n",
    "Often times, you may not want to simply apply every function to all columns. If our columns are of different types, we may only want to apply certain parts of the pipeline to a subset of columns. This is what we saw in the two previous exercises. One set of transformations are applied to numeric columns and another set to the categorical ones. We can use scikit-learn‘s ColumnTransformer as one way of combining these processes together.\n",
    "\n",
    "ColumnTransformer takes in a list of tuples of the form (name, pipeline, columns):\n",
    "\n",
    "example_column_transformer = ColumnTransformer(\n",
    "    transformers=[ (\"name_1\", pipeline_1, columns_1),\n",
    "                   (\"name_2\", pipeline_2, columns_2)])\n",
    "\n",
    "The transformer can be anything with a .fit and .transform method like we used previously (like SimpleImputer or StandardScaler), but can also itself be a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score method of the pipeline object\n",
    "\n",
    " But now the final step also has a .predict method, which can be called on the entire pipeline! Additionally the .score() method, which estimates the default prediction score on any scikit-learn model can also be used to evaluate the performance of the pipeline.\n",
    "\n",
    " pipeline_score = pipeline.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Great, we have a very condensed bit of code that does all our data cleaning, preprocessing, and modeling in a reusable fashion! What now? Well, we can tune some of the parameters of the model by applying a grid search over a range of hyperparameter values.\n",
    "\n",
    "A linear regression model has very few hyperparameters and here we’ll be using the hyperparameter that pertains to whether we include an intercept or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.io import arff\n",
    "\n",
    "data = arff.loadarff('bone-marrow.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df.drop(columns=['Disease'], inplace=True)\n",
    "\n",
    "\n",
    "#Convert all columns to numeric, coerce errors to null values\n",
    "for c in df.columns:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    \n",
    "#Make sure binary columns are encoded as 0 and 1\n",
    "for c in df.columns[df.nunique()==2]:\n",
    "    df[c] = (df[c]==1)*1.0\n",
    "\n",
    "# 1. Calculate the number of unique values for each column\n",
    "print('Count of unique values in each column:', df.nunique())\n",
    "\n",
    "# 2. Set target, survival_status,as y; features (dropping survival status and time) as X\n",
    "y = df[\"survival_status\"]\n",
    "X = df.loc[:,~df.columns.isin([\"survival_time\",\"survival_status\"])]\n",
    "\n",
    "# 3. Define lists of numeric and categorical columns based on number of unique values\n",
    "num_cols = X.columns[X.nunique() > 7].tolist()\n",
    "cat_cols = X.columns[X.nunique() <= 7].tolist()\n",
    "\n",
    "# 4. Print columns with missing values\n",
    "print(X.isnull().sum()>0)\n",
    "\n",
    "# 5. Split data into train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=66)\n",
    "\n",
    "# 6. Create categorical preprocessing pipeline\n",
    "# Using mode to fill in missing values and OHE\n",
    "cat_vals = Pipeline([\n",
    "    (\"imp_cat\", SimpleImputer(strategy=\"most_frequent\")),  \n",
    "    (\"ohe\", OneHotEncoder(sparse=False, drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Create numerical preprocessing pipeline\n",
    "# Using mean to fill in missing values and standard scaling of features\n",
    "num_vals = Pipeline([(\"imp_num\",SimpleImputer(strategy='mean')),(\"scaler\", StandardScaler())])\n",
    "\n",
    "# 8. Create column transformer that will preprocess the numerical and categorical features separately\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"cat_vals\", cat_vals, cat_cols),  \n",
    "    ('num_vals', num_vals, num_cols)\n",
    "])\n",
    "\n",
    "\n",
    "# 9. Create a pipeline with preprocess, PCA, and a logistic regresssion model\n",
    "\n",
    "pipeline = Pipeline([(\"preprocess\",preprocess), \n",
    "                     (\"pca\", PCA()),\n",
    "                     (\"clf\",LogisticRegression())])\n",
    "\n",
    "# 10. Fit the pipeline on the training data\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "#Predict the pipeline on the test data\n",
    "print(pipeline.score(X_test,y_test))\n",
    "# 11. Define search space of hyperparameters\n",
    "\n",
    "#12. Search over hyperparameters abolve to optimize pipeline and fit\n",
    "search_space = [{\"pca\":[PCA()],\"pca__n_components\":np.linspace(30,37,3).astype(int)},\n",
    "{\"logreg\":[LogisticRegression()],\"logreg__penalty\":[\"l1\",\"l2\",\"elasticnect\"],\"logreg__C\":[0,0.1,1,10]}]\n",
    "\n",
    "pipeline_cv = Pipeline([(\"preprocess\",preprocess), \n",
    "                     (\"pca\", PCA()),\n",
    "                     (\"logreg\",LogisticRegression())])\n",
    "\n",
    "gs = GridSearchCV(estimator=pipeline_cv,              param_grid=search_space,\n",
    "scoring = \"roc_auc\",cv=4)\n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "# 13. Save the best estimator from the gridsearch and print attributes and final accuracy on test set\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "# 14. Print attributes of best_model\n",
    "print(\"The values of the hyperparameters for the pca are: \", best_model.named_steps['pca'].get_params())\n",
    "\n",
    "print(\"The values of the hyperparameters for the logistic regression are: \", best_model.named_steps['logreg'].get_params())\n",
    "\n",
    "# 15. Print final accuracy score \n",
    "print(\"The score on the test set\", best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
