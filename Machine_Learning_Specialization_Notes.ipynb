{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef18b7b7",
   "metadata": {},
   "source": [
    "## Machinle Learning by Stanford University and DeepLearning. Ai ##\n",
    "Machine Learnig Specialization by Andrew Ng.  \n",
    "Notes by C√©sar Muro Cabral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7936f",
   "metadata": {},
   "source": [
    " Machine learning (ML) is part of applied mathematics and computer science. It uses tools from mathematical disciplines such as probability, statistics, and optimization theory to extract patter from data.\n",
    "\n",
    " The main idea behind machine learning is learnig from examples: we prepare a dataset with examples, and a machine learning systems 'learns' from this dataset. In other words, we give the system the input and desired output, and the system tries to figure out how to do the conversion automatically, without asking a human. \n",
    " \n",
    " Then we provide a machine learning model with the training model. This process is called training or sometimes fitting. When training is done, we can use the model by asking it.\n",
    " \n",
    " In ML the difficult work is done by the machine; we need only supervise the training process to make sure that the model is good. To use ML we need to have data. If no data is avaliable, ML is not possible.\n",
    " \n",
    " In supervised ML we provide the model with features, we supervise or teach the model by showing it examples. We can express ML mathematically as  \n",
    " $$ y=g(X) $$\n",
    "where $ g $ is the function that we want to learn with machine learning, $X$ is the feature matrix in which rows are feature vectors, and $y$ is the target variable: a vector. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d13c0",
   "metadata": {},
   "source": [
    "**Machine Learning** is the science of getting computers to learn without being explicitly programmed. It is a subfield of IA.  \n",
    "Machine learning is the field of study that gives computers the hability to learn without being explicitly programmed.  \n",
    "In general, the more opportunities you give your algorithm to learn the better it will perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792b89f",
   "metadata": {},
   "source": [
    "Note: Sometime in future building machines as intelligent as you or me. This is sometimes called Artificial General Intelligence or AGI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24510ea7",
   "metadata": {},
   "source": [
    "The two main types of machine learnin algorithms are:  \n",
    "* Supervised learning: It is the most used in real world applications,and it has seen the most rapid avancements and innovations.\n",
    "\n",
    "\n",
    "* Unsupervised learning: Recommender systems. Reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ddc848",
   "metadata": {},
   "source": [
    "The machine learning process has six steps:  \n",
    "  \n",
    "1 **Business understanding**  \n",
    "  \n",
    "2 **Data understanding**: The next step is data understanding. Here, we try to identify the data sources we can\n",
    "use to solve the problem.    \n",
    "  \n",
    "3 **Data preparation**: In this step, we clean the data, transforming it in such a way that it can be used as\n",
    "input for a machine learning model.    \n",
    "  \n",
    "4 **Modeling**: We decide which machine learning model to use and how to make sure\n",
    "that we get the best out of it. We need to know how we will measure the performance of the models to select the\n",
    "best one. It‚Äôs very likely that in this step, we need to go back and adjust the way we prepare the data. Perhaps we came up with a great feature, so we go back to the data preparation step to write some code to compute that feature. When the code is done, we train the model again to check whether this feature is good. The goal at this step is to produce a model in such a way that it achieves the best predictive performance.  \n",
    "  \n",
    " A better approach for selecting the best model before deploying it is emulating the scenario of going live. We get our complete dataset, take a part out of it, and train the model on the remaining part of the data. When the training is done, we pretend that the held-out dataset is the new, unseen data, and we use it to measure the performance of our models. This part of data is often called the *validation set*, and the process of keeping part of a dataset away and using it to evaluate performance is called *validation*.  \n",
    "      \n",
    "5 **Evaluation**: In this step, we check whether the model lives up to expectations. When we set the goal in the business understanding step, we also define the way of establishing whether the goal is achieved. Typically, we do this by looking at an important business metric and making sure that the model moves the metric in the right direction. \n",
    "  \n",
    "How do we select the best model with the best parameters? To do so, we use the same evaluation scheme. We train the models with different parameters on the training data, apply them to the validation data, and then select the model and its parameters based on the best validation results. \n",
    "     \n",
    "6 **Deployment**: The best way to evaluate a model is to battle-test it: roll it out to a fraction of users and\n",
    "then check whether our business metric changes for these users.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a55a7a",
   "metadata": {},
   "source": [
    "The process of selecting the best model and the best parameters for the model is\n",
    "called **model selection**. We can summarize model selection as follows:  \n",
    "  \n",
    "1 We split the data into training, validation, and testing parts.  \n",
    "  \n",
    "2 We train each model first on the training part and then evaluate it on validation.  \n",
    "  \n",
    "3 Each time we train a different model, we record the evaluation results using the\n",
    "validation part.  \n",
    "  \n",
    "4 At the end, we determine which model is the best and test it on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50440a04",
   "metadata": {},
   "source": [
    "# SUPERVISED MACHINE LEARNING  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3371de4",
   "metadata": {},
   "source": [
    "Andrew thinks that the 99% of the economic value created by machine learning is through supervised machine learning.  \n",
    "\n",
    "Supervised machine learning refers to algorithms to learn $ x (input) \\rightarrow y(output) $ mappings. \n",
    "The key characteristic of supervised learning is that you give your learning algorithm examples to learn from that includes the right answer. The task of the learning algorithm is to produce more right answers.  \n",
    "\n",
    "A particular type of supervised learning is Regression: Predict a number from infinitely many possible numbers.  \n",
    "\n",
    "The second type of supervised learning problem is Clasification. Clasification algorithms predict categories which are a small finite set. The terms output classes and output categories are often used interchangeably\n",
    "\n",
    "The most lucrative form of supervised learning today is probably used in online advertising. Nearly all the large online ad platforms have a learning algorithm that inputs some information about an ad and some information about you and then tries to figure out if you will click on that ad or not. Because by showing you ads they're just slightly more likely to click on, for these large online ad platforms, every click is revenue, this actually drives a lot of revenue for these companies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece75a5",
   "metadata": {},
   "source": [
    "A bit more formally, we can express a supervised machine learning model mathematically as  \n",
    "$$y\\sim g(X),$$  \n",
    "where $g$ is the function that we want to learn, $X$ is the feature matrix in which rows, and $y$ is the target variable, a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27459062",
   "metadata": {},
   "source": [
    "The goal of machine learning is to learn this function $g$ in such a way that when it gets the matrix $X$, the output is close to the vector $y$. In other words, the function $g$ must be able to take in $X$ and produce $y$. The process of learning g is usually called *training* or *fitting*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b69176",
   "metadata": {},
   "source": [
    "## Unsupervised machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616c279",
   "metadata": {},
   "source": [
    "The most widely used form of machine learning is unsupervised learning. Andrew says that unsupervised learning is just super supervised machine learning. It find patterns or structures that might me in this data. We don't provide the right answer.    \n",
    "\n",
    "\n",
    "An unsupervised algorithm might decided that data can be assigned to two different groups or two different clusters. it is called **clustering algorithm**. It is used, for example, in google news.  \n",
    "\n",
    "Then, in unsupervised learning data only comes with inputs x, but not output labels y. Algorithm has to find the structure of data. Other two types of unsupervised algorithms are anomaly detection, which find unusual data points, and dimensionality reduciton, which compress data using fewer numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe4019",
   "metadata": {},
   "source": [
    "## Linear regression model with one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d5eaa7",
   "metadata": {},
   "source": [
    "It just means fitting a straight line to our data.  \n",
    "Another name is univariate linear regression.  \n",
    "  \n",
    "Recall that regression models predicts numbers.  \n",
    "\n",
    "The data used to train the model is named *training set*. Then to predict, we first train the model to learn from the training set and the our model can make predicitons.    \n",
    "  \n",
    "Notation:  \n",
    "$x$: input variable, or input feature.  \n",
    "$y$: out put variable, or target variable.  \n",
    "$m$: number of training examples.\n",
    "  \n",
    "Then, we create a function $\\hat{y}=f(x)$ where $\\hat{y}$ is the estimate or the prediciton for $y$. The function $f$ is called the model.  \n",
    "  \n",
    "In the case of linear fitting the model (linear) function is:  \n",
    "$$f(x)=f_{w,b}(x)=wx+b$$  \n",
    "$w$, and $b$ are the parameters of the model. Recall that $w$ is the slope of the line and $b$ the $y$-axis interception. \n",
    "$x$ are the input features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c56ff",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774ec4c",
   "metadata": {},
   "source": [
    "It tells us how well the model is doing.  \n",
    "\n",
    "Im machine learning parameters of the model are the variable you can adjust during training in order to imporve the model. They also are referred as *weights* or *coefficients*.  \n",
    "  \n",
    "  The cost function takes the prediction $\\hat{y}$ and compares it with the target $y$ by taking the sum of square of the residuals, i.e. $$J(w,b)=\\frac{1}{2m}\\sum^{m}_{i=1}(y_{i}-\\hat{y}_{i})^{2},$$ where we denotate $J(w,b)$ as the cost function, and $\\hat{y}_{i}=f_{w,b}(x_{i})$. This is also called *the squared error cost function*.  \n",
    "  \n",
    " We want the parameters such that minimize the cost function $J(w,b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5331d",
   "metadata": {},
   "source": [
    "We can visualize $J(w,b)$ as a 3D function with variables $w$ and $b$. A convenient way to visualize a 3D plot is with a Counter Plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959f411",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523617c9",
   "metadata": {},
   "source": [
    "A systematic way to find the values of the parameter that fit the model. There is the algorithm *gradient descent*. It is also used to train deep learning models.   \n",
    "\n",
    "Gradient descent allows us to minimize any function $J(w_{1},w_{2},...,w_{n},b)$.  \n",
    "  \n",
    "Outline:  \n",
    "* Start with initial guesses of the parameters.  \n",
    "* Keep changing the parameters to reduce $J$.  \n",
    "* Until we settle at or near minimum.  \n",
    "  \n",
    "  \n",
    "Then, the algorithm follows the expression (the sign = is in programming context not in rigid math context)\n",
    "$$tempw=w-\\alpha \\frac{\\partial}{\\partial w} J(w,b), $$  \n",
    "$$tempb=b-\\alpha \\frac{\\partial}{\\partial b}J(w,b),$$\n",
    "$$w=tempw,\\quad b=tempb$$\n",
    "where $\\alpha$ is the *learning rate* which is usually a small positive number between 0 and 1. It controls how big of a step you take downhill.  \n",
    "We simultaneously update $w$ and $b$ and repeat until convergence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c90270",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd2e6b",
   "metadata": {},
   "source": [
    "The choice of the learning rate, alpha will have a huge impact on the efficiency of your implementation of gradient descent.\n",
    "And if alpha, the learning rate is chosen poorly rate of descent may not even work at all.  \n",
    "  \n",
    "If we take $\\alpha$ very very small, then we end up taking small baby steps, and the following step is also minuscule. The result is that we end up decreasing the cost function $J$ but incredoble slowly; Gradient descent may be slow.  \n",
    "  \n",
    "If $\\alpha$ is too large we get further and further away from the minimum. Gradient descent  fail to converge, diverge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811937e",
   "metadata": {},
   "source": [
    "# Regression with multiple input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105d2dc",
   "metadata": {},
   "source": [
    "Now we have $n$ features, i.e. $x_{j},\\quad j=1,...,n$ features to predict $y$.  \n",
    "\n",
    "Moreover, $\\vec{x}^{\\,(i)}$ denotes features of the $i^{th}$ training example.  \n",
    "  \n",
    "Now, our linear model takes the form:\n",
    "$$f_{w,b}(\\vec{x})=w_{1}x_{1}+w_{2}x_{2}+...+w_{n}x_{n}+b$$.  \n",
    "  \n",
    "We can define the vector $\\vec{w}=(w_{1},w_{2},...,w_{n})$. Then $\\vec{w}$ and $b$ are the parameters of the model.  \n",
    "  \n",
    "Then the model easily reads as $f_{\\vec{w},b}=\\vec{w}\\cdot\\vec{x}+b$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf100e4",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c42cd",
   "metadata": {},
   "source": [
    "In Python you can define a vector with the function np.array(), for example np.array([1,2,3,4]).  \n",
    "The dot product between to vectors $\\vec{w}$ and $\\vec{x}$ can be written in Python as np.dot(w,x)  \n",
    "  \n",
    "  Then, our model takes the form $f=np.dot(w,x)+b$.  \n",
    "    \n",
    " With vectorization the computer acts in parallel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b1cc2",
   "metadata": {},
   "source": [
    "Now, the cost funciton is a function of $\\vec{w}$, i.e. $J(\\vec{w},b)$, and the gradient descent is written as \n",
    "$$tempw_{j}=w_{j}-\\alpha \\frac{\\partial}{\\partial w_{j}} J(\\vec{w},b), $$  \n",
    "$$tempb=b-\\alpha \\frac{\\partial}{\\partial b}J(\\vec{w},b),$$\n",
    "$$w=tempw,\\quad b=tempb$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876a70c",
   "metadata": {},
   "source": [
    "# Gradient descent in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012a3c4",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53098cb1",
   "metadata": {},
   "source": [
    "Then, how scale features?  \n",
    "  \n",
    "* One way is that if we have $x_{min}\\leq x \\leq x_{max}$ then $x_{scaled}=\\frac{x}{x_{max}}$.  \n",
    "  \n",
    "* Mean normalization: $x_{scaled}=\\frac{x-\\mu}{x_{max}-x_{min}}$.  \n",
    "\n",
    "* Z-score normalization: $x_{scaled}=\\frac{x-\\mu}{\\sigma}$.  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd46466",
   "metadata": {},
   "source": [
    "## Checking gradient descent for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95085e",
   "metadata": {},
   "source": [
    "Making sure that gradient descent is working well. One way is plotting the # of iterations vs J. Then it shoould tends to zero as increasing the numer of iterations. The curve is called *learning curve*.  \n",
    "  \n",
    "  If $J$ ever increases after one iteration that means either $\\alpha$ is choosen poorly and it usually means $\\alpha$ is too large or there could be a bug in the code.\n",
    "  \n",
    "  An approach is to performa an automatic convergence test. Let $\\epsilon$ a small number, then if $J\\leq \\epsilon$ declare convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3e078",
   "metadata": {},
   "source": [
    "The learning algorithm will run much better with an appropiate choice of learning rate.  \n",
    "\n",
    "**Values of $\\alpha$ to try**: 0.001, 0.01, 0.1, 1.  \n",
    "\n",
    "Choose $\\alpha$ too small, then big and choose between them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1340d1a9",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06a6c4",
   "metadata": {},
   "source": [
    "Using intuition to design new features, by transforming or combining original features is called feature engineering.  \n",
    "To improve our model further, we can add more features to the model: we create others and add them to the\n",
    "existing features. As we already know, this process is called feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937c9c8",
   "metadata": {},
   "source": [
    "## Poynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0a69d",
   "metadata": {},
   "source": [
    "Now we fit with a polynomial $f_{\\vec{w},b}=b+w_{1}x+w_{2}x^{2}+w_{3}x^{3}+...$.  \n",
    "It is important to apply feature scaling to get the features into comparable ranges of values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b0d7ca",
   "metadata": {},
   "source": [
    "# Classification with logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3560ee7",
   "metadata": {},
   "source": [
    "Class=category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64156371",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e117a57",
   "metadata": {},
   "source": [
    "We have two categorical variables, let us say 0 and 1.  \n",
    "We fit a S-shaped curve called the *logistic function* or *sigmoid function* \n",
    "$$g(z)=\\frac{1}{1+e^{-z}},\\quad 0<g(z)<1.$$  \n",
    "  \n",
    "  In the logistic regression model $z=\\vec{w} \\cdot\\ \\vec{x}+b$, then\n",
    " $$g(z=\\vec{w} \\cdot\\ \\vec{x}+b)=\\frac{1}{1+e^{-(\\vec{w} \\cdot\\ \\vec{x}+b)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4771968",
   "metadata": {},
   "source": [
    "Think logist regression function as outputing the probability that the class or the label $y$ will be equal to 1 given a certain input $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65728e5",
   "metadata": {},
   "source": [
    "## Decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301bcc6",
   "metadata": {},
   "source": [
    "Define the treshold. With the sigmoid function a common choice would be to pick 0.5.  \n",
    "  \n",
    "  The model predicts 1 whenever $\\vec{w}\\cdot \\vec{x}+b \\geq 0$. Conversely, when $$\\vec{w}\\cdot \\vec{x}+b \\leq 0$$ the model predicts $y=0$.  \n",
    "  The point where $z=\\vec{w} \\cdot \\vec{x}+b=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081e572",
   "metadata": {},
   "source": [
    "## Cost function for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea622e",
   "metadata": {},
   "source": [
    "The square error function is not the ideal for logistic regression. Set $m$ as the number of training examples and $n$ the number of features, with the logistic regression model $f_{\\vec{w},b}=\\frac{1}{1+e^{-(\\vec{w} \\cdot \\vec{x}+b)}}$.   \n",
    "  \n",
    "By employing the same function $J(\\vec{w},b)=\\frac{1}{2m}\\sum_{i=1}^{m}(f_{\\vec{w},b}(x^{(i)})-y^{(i)})$ the non-linear nature of the model results in a ‚Äúwiggly‚Äù, non-convex cost function with many potential local minima.  \n",
    "\n",
    "We define the general form of the logistic loss function as \n",
    "$$L(f_{\\vec{w},b}(\\vec{x}^{(i)}),y^{(i)})=-log(f_{\\vec{w},b}(\\vec{x}^{(i)})) \\quad if y^{(1)}=1$$\n",
    "$$ =-log(1-f_{\\vec{w},b}(\\vec{x}^{(i)}))\\quad if y^{(i)}=0.   $$\n",
    "The further prediction $f_{\\vec{w},b}(\\vec{x},b)$ is from target $y^{(i)}$, the higher the loss.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452446dd",
   "metadata": {},
   "source": [
    "**Simplified cost function**  \n",
    "The loss function takes the simplified form \n",
    "$$ L(f_{\\vec{w},b}(\\vec{x}^{(i)}),y^{(i)})=-y^{(i)}log(f_{\\vec{w},b}(\\vec{x}^{(i)}))-(1-y^{(i)})log(1-f_{\\vec{w},b}(\\vec{x}^{(i)})), $$ \n",
    "  \n",
    "and the cost function: \n",
    "$$J(\\vec{w},b)=\\frac{1}{m} \\sum^{m}_{i=1}[L(f_{\\vec{w},b}(\\vec{x}^{(i)}),y^{(i)})] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b2518",
   "metadata": {},
   "source": [
    "**Gradient descent implementation - Training logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71940b2f",
   "metadata": {},
   "source": [
    "Then, our lost function is  \n",
    "$$J(\\vec{w},b)=-\\frac{1}{m}\\sum_{i=1}^{m}[ y^{(i)}log(f_{\\vec{w},b}(\\vec{x}^{(i)})) +(1-y^{(i)})log(1-f_{\\vec{w},b}(\\vec{x}^{(i)})) ]  $$  \n",
    "and the algorithm of gradient descent  \n",
    "repeat {\n",
    "$$  w_{j}=w_{j}-\\alpha \\frac{\\partial}{\\partial w_{i}} J(\\vec{w},b)  $$  \n",
    "$$ b=b-\\alpha \\frac{ \\partial }{\\partial b} J(\\vec{w},b)  $$ \n",
    "} $j=1,2,...,n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7aaf3",
   "metadata": {},
   "source": [
    "## The problem of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e56ff0",
   "metadata": {},
   "source": [
    "When the data does not fit well the problem is called *underfitting* or *high-bias*.    \n",
    "  \n",
    "If the learning algorithm has very strong preconception and fits the data perfectly but the result are wiggly curves. When a model fits the training data well but does not work well with new examples that are not in the training set. This is called overfitting. Another terms is that the algorithm has high variance.  \n",
    "  \n",
    "We can say that the objective of machine learning is to get a model that is not under fitting or over fitting  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de35310c",
   "metadata": {},
   "source": [
    "**Regularization to reduce overfitting**   \n",
    "\n",
    "* One way to overcome this problem is collecting more data.  \n",
    "  \n",
    "* Another option is to see if you can use fewer features. Choosing the most appropiate set of features to use is sometimes called *feature selection*.   \n",
    "  \n",
    "* *Regularization*: Reduce the size of the parameters $w_{j}$. It prevents the features having an overly large effect   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d85786",
   "metadata": {},
   "source": [
    "**Cost function with regularization**  \n",
    "Adding smaller values for the parameters $w_{1},...,w_{n},b$. We penalize all the $w_{j}$ parameters.  \n",
    "$$J(\\vec{w},b)=\\frac{1}{2m}\\sum_{i=1}^{m}(f_{\\vec{w},b}(\\vec{x}^{(i)})-y^{(i)})+\\frac{\\lambda}{2m} \\sum_{j=1}^{n}w_{j}^{2} $$  \n",
    "$\\lambda>0$ is the *regularization parameter*. By convention we are not penalizing the parameter $b$. The parameter $\\lambda$ balances keeping $w_{j}$ small and fitting the data. Increasing the regularization parameter lambdalambda reduces overfitting by reducing the size of the parameters.  For some parameters that are near zero, this reduces the effect of the associated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3903f32",
   "metadata": {},
   "source": [
    "## Regularized linear regression  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a40e2f7",
   "metadata": {},
   "source": [
    "Then, our cost function for linear regression is  \n",
    "$$J(\\vec{w},b)=\\frac{1}{2m}\\sum_{i=1}^{m}(f_{\\vec{w},b}(\\vec{x}^{(i)})-y^{(i)})+\\frac{\\lambda}{2m} \\sum_{j=1}^{n}w_{j}^{2} $$ and we add to the algorithm  \n",
    "repeat {\n",
    "$$  w_{j}=w_{j}-\\alpha \\frac{\\partial}{\\partial w_{i}} J(\\vec{w},b)  $$  \n",
    "$$ b=b-\\alpha \\frac{ \\partial }{\\partial b} J(\\vec{w},b)  $$ \n",
    "} $j=1,2,...,n$.  \n",
    "Then, we have an extra term in the $w_{j}$ that reads as $w_{j}\\left(1- \\alpha \\frac{\\lambda}{m} \\right)$ which decreases the value of $w_{j}$ each iteration by a little bit.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01616600",
   "metadata": {},
   "source": [
    "## Regularized logistic linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc38851",
   "metadata": {},
   "source": [
    "The gradient descent update is very similar for this case. We just add the extra term $\\frac{\\lambda}{2m}\\sum_{j=1}^{n}w_{j}^{2}$, i.e.  \n",
    "$$J(\\vec{w},b)=-\\frac{1}{m}\\sum_{i=1}^{m}[ y^{(i)}log(f_{\\vec{w},b}(\\vec{x}^{(i)})) +(1-y^{(i)})log(1-f_{\\vec{w},b}(\\vec{x}^{(i)})) ]+\\frac{\\lambda}{2m} \\sum_{j=1}^{n}w_{j}^{2} $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0b129",
   "metadata": {},
   "source": [
    "# ADVANCED ALGORTIHMS - Course 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d232d09",
   "metadata": {},
   "source": [
    "Origins: Algorithms that try to mimic the brain.  \n",
    "  \n",
    "The first application area of deep learning and had huge impact on was probably speech recognition. Then evolves to computer vision and after text (NLP) and so on.    \n",
    "  \n",
    "  Artifical neural networks uses a very simplified mathematical model of a neuron. The \"neuron\" takes 1 or more inputs , it does some computation, and it ouputs some other number which then could be an input to be a second neuron. In DL we want to simulate many such neurons at the same time. \n",
    "      \n",
    "For certain types of application where we have a lot of data and we are able to train a very large neural network we can take advantage of that huge amount of data the we could attain performance on anything.         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21283e",
   "metadata": {},
   "source": [
    "  \n",
    "Another way to think of a neuron is as a tiny little computer whose only job is to input one number or a few numbers and the to output one number or maybe few other numbers.  \n",
    "  \n",
    "We group the neurons in *layers*, which take as inputs the features. A layer can have multiple neurons or a single neuron. The last layer is called output layer. The set of the input feautures is called input layer. Each neuron in the layer has as input every previous feature.  \n",
    "  \n",
    "Notation: input layer $\\vec{x}$. For the *activion values* we use the notation $\\vec{a}$, to finally obtain a scalar $a$. The layer in the middle is called hidden layer.  \n",
    "  \n",
    "We can think neural networks as logistic regression that learn its own features.  \n",
    " \n",
    "Summarizing, a neural network takes a input layer which is a vector a features. It is input to a hidden layer which produces another vector with new features called activitions. Then this activions are input for the last layer which produces and scalar named final activation.  \n",
    "\n",
    "Architecture for a neural network. The numbers of layers, number of neurons per layer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4691b2",
   "metadata": {},
   "source": [
    "## Neural network model  - Week 1\n",
    "\n",
    "\n",
    "**Neural network layer**  \n",
    "  \n",
    "The fundamental building block of most modern neural networks is a layer of neurons. \n",
    "  \n",
    "We will emplot the notation with superscripts of the form $[x]$ for layer numbering with number x.  Then, $\\vec{a}^{1}$ is the ouyput of layer 1 and the input of layer 2. If the layer 2 only has one neuron which applies the sigmoid function, then the output is the scalar $a_{1}=g(\\vec{w}_{1}\\cdot \\vec{a}_{1}+b_{1})$.  \n",
    "  \n",
    "So that's how a neural network works. Every layer inputs a vector of numbers and applies a bunch of logistic regression units to it, and then computes another vector of numbers that then gets passed from layer to layer until you get to the final output layers computation, which is the prediction of the neural network. Then you can either threshold at 0.5 or not to come up with the final prediction.  \n",
    "  \n",
    "**More complex neural networks**  \n",
    "By convetion when we say a neural network has $n$ layers, that includes all the hidden layers and output layer, but we don't count the hidden layer.  \n",
    "  \n",
    "Suppose we have 4 layers. Layer 3 inputs a vector $\\vec{a}^{[2]}$. The output is a vector $\\vec{a}^{3}=[a_1,a_2,a_3]$ where $a_{1}^{[3]}=g(\\vec{w}_{1}^{[3]}\\cdot \\vec{a}^{[2]}+b_{1}^{[3]})$, $a_{2}^{[3]}=g(\\vec{w}_{2}^{[3]}\\cdot \\vec{a}^{[2]}+b_{2}^{[3]})$, ... . In general, the activation of layer $l$ and unit $j$ is $a_{j}^{[l]}=g(w^{[l]}_{j}\\cdot \\vec{a}^{[l-1]}+\\vec{b}^{[l]}_{j})$. In this case the *activation function* is the sigmoid function.  \n",
    "Recall that $\\vec{a}^{[0]}=\\vec{x}$. \n",
    "  \n",
    "**Inference: making predictions (forward propagation)**  \n",
    "When computation goes from left to right throug a serie of layers, the algorithm is called forward propagation, because we are propagating the activitions of the neurons. The network architecture with more hidden units initially and then the number of units decreases as you get closer to the output layer is common. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b096493e",
   "metadata": {},
   "source": [
    "**Tensorflow and Keras**  \n",
    "Tensorflow is a machine learning package developed by Google. In 2019, Google integrated Keras into Tensorflow and released Tensorflow 2.0. Keras is a framework developed independently by Fran√ßois Chollet that creates a simple, layer-centric interface to Tensorflow. This course will be using the Keras interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)  # 2-D Matrix\n",
    "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)  # 2-D Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500db398",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "X_train[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07516bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "ax.scatter(X_train[pos], Y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\n",
    "ax.scatter(X_train[neg], Y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', \n",
    "              edgecolors=\"blue\",lw=3)\n",
    "\n",
    "ax.set_ylim(-0.08,1.1)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_title('one variable plot')\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b6369",
   "metadata": {},
   "source": [
    "We can implement a 'logistic neuron' by adding a sigmoid activation. This section will create a Tensorflow Model that contains our logistic layer to demonstrate an alternate method of creating models. Tensorflow is most often used to create multi-layer models. The Sequential model is a convenient means of constructing these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71bcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1, input_dim=1,  activation = 'sigmoid', name='L1')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01d7b1",
   "metadata": {},
   "source": [
    "model.summary() shows the layers and number of parameters in the model. There is only one layer in this model and that layer has only one unit. The unit has two parameters, ùë§ and ùëè."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ccbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ce4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_layer = model.get_layer('L1')\n",
    "w,b = logistic_layer.get_weights()\n",
    "print(w,b)\n",
    "print(w.shape,b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "# set_weights takes a list of numpy arrays\n",
    "logistic_layer.set_weights([set_w, set_b])\n",
    "print(logistic_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = model.predict(X_train[0].reshape(1,1))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a061a",
   "metadata": {},
   "source": [
    "**Tensorflow and Keras implementation - Inference on code**  \n",
    "Tensorflow stores data in tensors.  \n",
    "Let us draw the general implementation:  \n",
    "\n",
    "import tensorflow as tf  \n",
    "x=np.array([...])  \n",
    "layer_1=Dense(units=25,activation='sigmoid')  \n",
    "layer_2=Dense(units=1,activation='sigmoid')  \n",
    "a1=layer_1(x) \n",
    "a2=layer_2(a1)\n",
    "  \n",
    "The function Dense() defines the layer, units argument is the number of neurons, and activation is the activation function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfad53",
   "metadata": {},
   "source": [
    "There are some inconsistencies between how data data is represented in TensorFlow and Numpy.  \n",
    "  \n",
    "Tensorflow uses tensors to represent the data, incluiding vectors which must be initialize as matrix, i.e. with 1xn dimensions arrays.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82962104",
   "metadata": {},
   "source": [
    "**Building a neural network architecture**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1440d54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc08de3ecc8a4db7b519fcd3581f30a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Mostrar/Cerrar C√≥digo', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06984ac580024898b96a0f60f9c29a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>C√≥digo oculto</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "button = widgets.Button(description=\"Mostrar/Cerrar C√≥digo\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(_):\n",
    "    with output:\n",
    "        display(display_id)\n",
    "        \n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "display(button)\n",
    "display_id = display(widgets.HTML('''<h3>C√≥digo oculto</h3>'''), display_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f71ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_cell_code(button_id):\n",
    "    \"\"\"\n",
    "    Adds a button to toggle (show/hide) the code cell but not the output. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    button_id : str\n",
    "        An identifier for cells that will hide/show when button is pressed.\n",
    "    \"\"\"\n",
    "    \n",
    "    from IPython.display import display_html\n",
    "    my_html = '''\n",
    "    <button type=\"button\" id=\"%s\" onclick=\"code_toggle('%s')\">Codigo</button>\n",
    "    <script>\n",
    "    function code_toggle(my_id) {\n",
    "        // get the parent element for the cell code and output\n",
    "        var p = $(\"#\"+my_id);\n",
    "        if (p.length==0) return;\n",
    "        while (!p.hasClass(\"cell\")) {\n",
    "            p = p.parent();\n",
    "            if (p.prop(\"tagName\") ==\"body\") return;\n",
    "        }\n",
    "    // get the cell code and toggle its value\n",
    "    var cell_code = p.find(\".input\");\n",
    "    cell_code.toggle();\n",
    "    }\n",
    "    </script>\n",
    "    ''' %(button_id, button_id)\n",
    "    return display_html(my_html, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac18da35",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <button type=\"button\" id=\"un_string_unico_y_reconocible\" onclick=\"code_toggle('un_string_unico_y_reconocible')\">Codigo</button>\n",
       "    <script>\n",
       "    function code_toggle(my_id) {\n",
       "        // get the parent element for the cell code and output\n",
       "        var p = $(\"#\"+my_id);\n",
       "        if (p.length==0) return;\n",
       "        while (!p.hasClass(\"cell\")) {\n",
       "            p = p.parent();\n",
       "            if (p.prop(\"tagName\") ==\"body\") return;\n",
       "        }\n",
       "    // get the cell code and toggle its value\n",
       "    var cell_code = p.find(\".input\");\n",
       "    cell_code.toggle();\n",
       "    }\n",
       "    </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toggle_cell_code(\"un_string_unico_y_reconocible\")\n",
    "\n",
    "X=np.array([[185.32,  12.69],\n",
    "       [259.92,  11.87],\n",
    "       [231.01,  14.41],\n",
    "       [175.37,  11.72],\n",
    "       [187.12,  14.13],\n",
    "       [225.91,  12.1 ],\n",
    "       [208.41,  14.18],\n",
    "       [207.08,  14.03],\n",
    "       [280.6 ,  14.23],\n",
    "       [202.87,  12.25],\n",
    "       [196.7 ,  13.54],\n",
    "       [270.31,  14.6 ],\n",
    "       [192.95,  15.2 ],\n",
    "       [213.57,  14.28],\n",
    "       [164.47,  11.92],\n",
    "       [177.26,  15.04],\n",
    "       [241.77,  14.9 ],\n",
    "       [237.  ,  13.13],\n",
    "       [219.74,  13.87],\n",
    "       [266.39,  13.25],\n",
    "       [270.45,  13.95],\n",
    "       [261.96,  13.49],\n",
    "       [243.49,  12.86],\n",
    "       [220.58,  12.36],\n",
    "       [163.59,  11.65],\n",
    "       [244.76,  13.33],\n",
    "       [271.19,  14.84],\n",
    "       [201.99,  15.39],\n",
    "       [229.93,  14.56],\n",
    "       [204.97,  12.28],\n",
    "       [173.19,  12.22],\n",
    "       [231.51,  11.95],\n",
    "       [152.69,  14.83],\n",
    "       [163.42,  13.3 ],\n",
    "       [215.95,  13.98],\n",
    "       [218.04,  15.25],\n",
    "       [251.3 ,  13.8 ],\n",
    "       [233.33,  13.53],\n",
    "       [280.24,  12.41],\n",
    "       [243.02,  13.72],\n",
    "       [155.67,  12.68],\n",
    "       [275.17,  14.64],\n",
    "       [151.73,  12.69],\n",
    "       [151.32,  14.81],\n",
    "       [164.9 ,  11.73],\n",
    "       [282.55,  13.28],\n",
    "       [192.98,  11.7 ],\n",
    "       [202.6 ,  12.96],\n",
    "       [220.67,  11.53],\n",
    "       [169.97,  12.34],\n",
    "       [209.47,  12.71],\n",
    "       [232.8 ,  12.64],\n",
    "       [272.8 ,  15.35],\n",
    "       [158.02,  12.34],\n",
    "       [226.01,  14.58],\n",
    "       [158.64,  12.24],\n",
    "       [211.66,  14.17],\n",
    "       [271.95,  14.97],\n",
    "       [257.16,  11.71],\n",
    "       [281.85,  13.96],\n",
    "       [161.63,  12.52],\n",
    "       [233.8 ,  13.04],\n",
    "       [210.29,  14.72],\n",
    "       [261.24,  13.69],\n",
    "       [256.98,  13.12],\n",
    "       [281.56,  13.92],\n",
    "       [280.64,  11.68],\n",
    "       [269.16,  13.74],\n",
    "       [246.34,  12.27],\n",
    "       [224.07,  12.66],\n",
    "       [164.24,  11.51],\n",
    "       [272.42,  14.18],\n",
    "       [177.68,  12.53],\n",
    "       [212.86,  14.77],\n",
    "       [165.88,  15.37],\n",
    "       [277.43,  12.48],\n",
    "       [236.51,  12.94],\n",
    "       [244.14,  11.85],\n",
    "       [213.45,  13.85],\n",
    "       [234.57,  14.27],\n",
    "       [270.34,  12.47],\n",
    "       [170.68,  13.06],\n",
    "       [226.79,  15.34],\n",
    "       [245.92,  14.45],\n",
    "       [281.32,  12.57],\n",
    "       [185.03,  13.19],\n",
    "       [189.88,  14.1 ],\n",
    "       [278.48,  12.11],\n",
    "       [219.92,  14.21],\n",
    "       [216.58,  15.15],\n",
    "       [249.48,  15.03],\n",
    "       [165.09,  12.28],\n",
    "       [158.87,  14.82],\n",
    "       [279.98,  11.56],\n",
    "       [256.55,  14.41],\n",
    "       [272.61,  12.58],\n",
    "       [246.49,  12.45],\n",
    "       [160.26,  14.48],\n",
    "       [155.7 ,  14.3 ],\n",
    "       [188.27,  13.45],\n",
    "       [270.36,  12.47],\n",
    "       [213.22,  12.92],\n",
    "       [175.7 ,  13.39],\n",
    "       [174.52,  14.7 ],\n",
    "       [233.  ,  12.63],\n",
    "       [281.37,  12.88],\n",
    "       [240.62,  14.43],\n",
    "       [185.81,  11.55],\n",
    "       [270.5 ,  15.33],\n",
    "       [172.98,  12.11],\n",
    "       [208.41,  13.89],\n",
    "       [283.51,  15.35],\n",
    "       [283.36,  12.48],\n",
    "       [230.85,  13.24],\n",
    "       [181.24,  11.76],\n",
    "       [172.78,  12.93],\n",
    "       [161.88,  12.1 ],\n",
    "       [156.03,  13.99],\n",
    "       [216.52,  12.47],\n",
    "       [221.06,  13.2 ],\n",
    "       [238.99,  15.23],\n",
    "       [197.69,  14.08],\n",
    "       [179.55,  15.26],\n",
    "       [233.39,  12.13],\n",
    "       [184.7 ,  12.14],\n",
    "       [174.18,  12.73],\n",
    "       [261.11,  13.33],\n",
    "       [187.42,  13.18],\n",
    "       [186.1 ,  14.43],\n",
    "       [157.94,  12.66],\n",
    "       [193.64,  12.23],\n",
    "       [249.65,  12.22],\n",
    "       [190.56,  11.73],\n",
    "       [252.  ,  12.96],\n",
    "       [238.55,  12.37],\n",
    "       [152.94,  12.79],\n",
    "       [255.17,  14.85],\n",
    "       [197.09,  14.89],\n",
    "       [156.8 ,  13.59],\n",
    "       [184.75,  13.26],\n",
    "       [179.92,  15.07],\n",
    "       [190.79,  15.28],\n",
    "       [164.73,  13.22],\n",
    "       [209.87,  14.34],\n",
    "       [196.58,  13.47],\n",
    "       [159.51,  12.74],\n",
    "       [247.87,  11.92],\n",
    "       [212.44,  12.45],\n",
    "       [172.34,  11.99],\n",
    "       [259.87,  14.25],\n",
    "       [201.23,  13.07],\n",
    "       [248.34,  13.92],\n",
    "       [273.66,  15.18],\n",
    "       [215.09,  14.14],\n",
    "       [223.53,  12.74],\n",
    "       [211.22,  14.38],\n",
    "       [224.61,  14.03],\n",
    "       [215.75,  15.31],\n",
    "       [254.82,  12.02],\n",
    "       [259.9 ,  15.17],\n",
    "       [260.25,  12.87],\n",
    "       [199.67,  12.47],\n",
    "       [157.52,  13.39],\n",
    "       [264.81,  14.58],\n",
    "       [239.4 ,  14.89],\n",
    "       [238.98,  12.39],\n",
    "       [258.43,  12.97],\n",
    "       [270.16,  12.81],\n",
    "       [162.41,  14.42],\n",
    "       [164.53,  14.98],\n",
    "       [205.61,  14.62],\n",
    "       [157.1 ,  13.68],\n",
    "       [241.38,  12.02],\n",
    "       [232.13,  12.07],\n",
    "       [191.04,  12.96],\n",
    "       [233.64,  12.02],\n",
    "       [174.95,  14.63],\n",
    "       [246.64,  13.32],\n",
    "       [188.07,  14.27],\n",
    "       [213.16,  12.75],\n",
    "       [268.08,  12.31],\n",
    "       [258.58,  13.97],\n",
    "       [237.21,  14.23],\n",
    "       [251.02,  15.02],\n",
    "       [274.28,  12.52],\n",
    "       [172.12,  15.09],\n",
    "       [177.52,  12.39],\n",
    "       [258.71,  15.36],\n",
    "       [264.01,  13.57],\n",
    "       [200.71,  15.45],\n",
    "       [249.37,  14.02],\n",
    "       [151.5 ,  12.28],\n",
    "       [151.82,  15.13],\n",
    "       [181.92,  12.18],\n",
    "       [228.65,  12.31],\n",
    "       [223.78,  15.3 ],\n",
    "       [266.63,  12.48],\n",
    "       [273.68,  13.1 ],\n",
    "       [220.61,  12.8 ],\n",
    "       [284.99,  12.73]])\n",
    "\n",
    "Y=np.array([[1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [1.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.],\n",
    "       [0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326afcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "020c5a43",
   "metadata": {},
   "source": [
    "### Normalize Data\n",
    "Fitting the weights to the data (back-propagation, covered in next week's lectures) will proceed more quickly if the data is normalized. This is the same procedure you used in Course 1 where features in the data are each normalized to have a similar range. \n",
    "The procedure below uses a Keras [normalization layer](https://keras.io/api/layers/preprocessing_layers/numerical/normalization/). It has the following steps:\n",
    "- create a \"Normalization Layer\". Note, as applied here, this is not a layer in your model.\n",
    "- 'adapt' the data. This learns the mean and variance of the data set and saves the values internally.\n",
    "- normalize the data.  \n",
    "It is important to apply normalization to any future data that utilizes the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Temperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c3390",
   "metadata": {},
   "source": [
    "Tile/copy our data to increase the training set size and reduce the number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47bce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.tile(Xn,(1000,1))\n",
    "Yt= np.tile(Y,(1000,1))   \n",
    "print(Xt.shape, Yt.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870880d",
   "metadata": {},
   "source": [
    "Let's build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "800efe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(2,)),\n",
    "        Dense(3, activation='sigmoid', name = 'layer1'),\n",
    "        Dense(1, activation='sigmoid', name = 'layer2')\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edd20f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 3)                 9         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127cb8a",
   "metadata": {},
   "source": [
    "Let's examine the weights and biases Tensorflow has instantiated.  The weights $W$ should be of size (number of features in input, number of units in the layer) while the bias $b$ size should match the number of units in the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f20e0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(2, 3):\n",
      " [[ 0.08334005 -0.29660565  0.17884266]\n",
      " [-0.56124383 -0.15262699  0.8899205 ]] \n",
      "b1(3,): [0. 0. 0.]\n",
      "W2(3, 1):\n",
      " [[-0.4277674 ]\n",
      " [-0.88499916]\n",
      " [ 0.3626454 ]] \n",
      "b2(1,): [0.]\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaadade",
   "metadata": {},
   "source": [
    "- The `model.compile` statement defines a loss function and specifies a compile optimization.\n",
    "- The `model.fit` statement runs gradient descent and fits the weights to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c15178fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 0.1783\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 0.1165\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 0.0426\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 0.0159\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 0.0103\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 0.0072\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 0.0052\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 0.0037\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 0.0027\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be8238c970>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train this neural network, all you need to do is call to\n",
    "#functions you need to call model dot compile with some parameters   \n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "model.fit(Xt,Yt,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543dad40",
   "metadata": {},
   "source": [
    "#### Epochs and batches\n",
    "In the `compile` statement above, the number of `epochs` was set to 10. This specifies that the entire data set should be applied during training 10 times.  During training, you see output describing the progress of training that looks like this:\n",
    "```\n",
    "Epoch 1/10\n",
    "6250/6250 [==============================] - 6s 910us/step - loss: 0.1782\n",
    "```\n",
    "The first line, `Epoch 1/10`, describes which epoch the model is currently running. For efficiency, the training data set is broken into 'batches'. The default size of a batch in Tensorflow is 32. There are 200000 examples in our expanded data set or 6250 batches. The notation on the 2nd line `6250/6250 [====` is describing which batch has been executed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce7e4f8",
   "metadata": {},
   "source": [
    "**Predicitons**  \n",
    "Once you have a trained model, you can then use it to make predictions. Recall that the output of our model is a probability. In this case, the probability of a good roast. To make a decision, one must apply the probability to a threshold. In this case, we will use 0.5.    \n",
    "Let's start by creating input data. The model is expecting one or more examples where examples are in the rows of matrix. In this case, we have two features so the matrix will be (m,2) where m is the number of examples.\n",
    "Recall, we have normalized the input features so we must normalize our test data as well.   \n",
    "To make a prediction, you apply the `predict` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67c632e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "predictions = \n",
      " [[9.875393e-01]\n",
      " [9.142362e-08]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_l(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ffe86",
   "metadata": {},
   "source": [
    "To convert the probabilities to a decision, we apply a threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b061159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "yhat = (predictions >= 0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6948a",
   "metadata": {},
   "source": [
    "## General implementation of forward propagation\n",
    "We construct manually a neural network of two layers using the sigmoid function as the activation function.\n",
    "We employ the same sets X,y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefbedbb",
   "metadata": {},
   "source": [
    "**Normalize data**  \n",
    "We need to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52e034bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Max, Min prenormalization: 284.99,151.32\n",
      "Duration Max, Min prenormalization: 1.00,0.00\n",
      "Temperature Max, Min post normalization: 1.66, -1.69\n",
      "Duration    Max, Min post normalization: 1.79, -1.70\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temperature Max, Min prenormalization: {np.max(X[:,0]):0.2f},{np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration Max, Min prenormalization: {np.max(Y[:,0]):0.2f},{np.min(Y[:,0]):0.2f}\")\n",
    "norm_l=tf.keras.layers.Normalization(axis=1)\n",
    "norm_l.adapt(X)\n",
    "Xn=norm_l(X)\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b7d3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(z):\n",
    "    g=1/(1+np.exp(-z))\n",
    "    return g\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e2b48",
   "metadata": {},
   "source": [
    "We will define the my_dense() function which computes the activations of a dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1878eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dense(a_in,W,b):\n",
    "    units=W.shape[1]\n",
    "    a_out=np.zeros(units)\n",
    "    for j in range(units):\n",
    "        w=W[:,j]\n",
    "        z=np.dot(w,a_in)+b[j]\n",
    "        a_out[j]=g(z)\n",
    "    return(a_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0c404",
   "metadata": {},
   "source": [
    "The following cell builds a two-layer neural network utilizing the `my_dense` subroutine above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2960a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential(x, W1, b1, W2, b2):\n",
    "    a1 = my_dense(x,  W1, b1)\n",
    "    a2 = my_dense(a1, W2, b2)\n",
    "    return(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584449da",
   "metadata": {},
   "source": [
    "We use the trained weights and biases from the code in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c684b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_tmp = np.array( [[-8.93,  0.29, 12.9 ], [-0.1,  -7.32, 10.81]] )\n",
    "b1_tmp = np.array( [-9.82, -9.28,  0.96] )\n",
    "W2_tmp = np.array( [[-31.18], [-27.59], [-32.56]] )\n",
    "b2_tmp = np.array( [15.41] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c9cee",
   "metadata": {},
   "source": [
    "Lets make some predictions using our layers and data of the roasted coffe. We define the function matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9983dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, W1, b1, W2, b2):\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08910873",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_tstn = norm_l(X_tst)  # remember to normalize\n",
    "predictions = my_predict(X_tstn, W1_tmp, b1_tmp, W2_tmp, b2_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f217360",
   "metadata": {},
   "source": [
    "To convert probabilites to a decision, we apply a treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce43edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "yhat = (predictions>=0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e87ec",
   "metadata": {},
   "source": [
    "**Neural networks are vectorized**  \n",
    "The function my_dense() is a matrix multiplication. The neural network layers are matrix multplications.   \n",
    "  \n",
    "If we define X,W, and B as matrix (with np arrays), then the code becomes: \n",
    "  \n",
    "def dense(A_in,W,B):  \n",
    "    Z=np.matmul(A_in,W)+B  \n",
    "    A_out=g(z)  \n",
    "    return A_out  \n",
    "    \n",
    "We can also write the matmul function as Z= A @ B.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1271a10",
   "metadata": {},
   "source": [
    "## Neural network training  - Week 2\n",
    "  \n",
    "Let us show how is the basic form of the code for a neural network of two layers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2519190",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols=1\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "model=Sequential()\n",
    "model.add(Dense(25,activation='sigmoid',input_shape=(n_cols,)))\n",
    "model.add(Dense(15,activation='sigmoid'))\n",
    "# The output layer\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "# To compile the model we need to specify the loss function\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "model.compile(loss='BinaryCrossentropy',optimizer='adam')\n",
    "#The last part is fitting the model\n",
    "#model.fit(x,y,epochs=10,valid_split_0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68afa4",
   "metadata": {},
   "source": [
    "Epoch: Number of steps in gradient descent.  \n",
    "Activation: Function to inference.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c556e",
   "metadata": {},
   "source": [
    "**Model training steps**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3be42",
   "metadata": {},
   "source": [
    "1.- Create the model  \n",
    "2.a Loss and cost functions. For binary classification we already now the logistic loss function $L(f(\\vec{x},y)=-ylog(f(\\vec{x}))-(1-y)log(1-f(\\vec{x}))$, which is also called *binary cross entropy*. In tensorflow we have the syntax  \n",
    "from tensorflow.keras.losses import BinaryCrossentropy    \n",
    "model.compile(loss=BinaryCrossentropy())  \n",
    "2.b In case of regression (predicting numbers): loss=MeanSquaredError()  \n",
    "3. Gradient descent. Tensorflow compute derivatives using backward propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abab352",
   "metadata": {},
   "source": [
    "### Alternatives to sigmoid activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37209e",
   "metadata": {},
   "source": [
    "Our neural network can be more powerful by choosing different acitvation functions.  \n",
    "With sigmoid function, whe choose $g(z)=g(\\vec{w}\\cdot\\vec{x}+b)$, now we take $g(x)=max(z,0)$ which is known as ReLu function. The linear activation function $g(z)=z$.  \n",
    "\n",
    "**Choosing activation function**  \n",
    "For the output layer, depends the type of variable we want to predict, the Andrew's criteria:  \n",
    "* Binary classification: Sigmoid function    \n",
    "* Regression y=+-: Linear activation function    \n",
    "* Regression y=+: ReLu activation function  \n",
    "  \n",
    "For the hidden layers, the most common acitvation function is the ReLu function since is not flat for positive values.  \n",
    "  \n",
    "Note: don't use linear activation in the hidden layers of the neural networks, it is likewise performing linear regression.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8153a",
   "metadata": {},
   "source": [
    "## Multiclass clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a1b4e",
   "metadata": {},
   "source": [
    "Classification problems with more of tow possible output labels; the target variable y can take on more than two possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417d055",
   "metadata": {},
   "source": [
    "The **softmax regression algorithm** is a generalization of logistic regression from binary classification to multiclass classification contexts. Suposse we have N target values $y=1,2,...,N$ (possible outputs), the softmax reads as   \n",
    "$$a_{j}=P(y=j,\\vec{x})=\\frac{e^{z_{j}}}{ e^{z_{1}}+e^{z_{2}}+e^{z_{3}}+e^{z_{4}}+\\dots+e^{z_{N}}  },\\quad j=1,2,\\dots,n$$  \n",
    " where $a_{1}+a_{2}+\\dots+a_{n}=1$.  \n",
    " The loss function, knowns as loss entropy function, is:  \n",
    " $$loss(a_{1},\\dots,a_{n})=-log a_{i}, \\quad if y=i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3972790",
   "metadata": {},
   "source": [
    "Then, we employ the softmax in the last ouput. The code reads as:  \n",
    "  \n",
    "import tensorflow as tf    \n",
    "from tensorflow.keras.models import Sequential    \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy  \n",
    "model=Sequential()  \n",
    "model.add(Dense(25,activation='relu'))  \n",
    "model.add(Dense(10,activation='relu'))  \n",
    "model.add(Dense(10,activation='softmax'))  \n",
    "model.compile(loss=SparseCategoricalCrossentropy())  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a5e7d",
   "metadata": {},
   "source": [
    "For multiclass classification, the recommended way to implement softmax regression is to set from_logits=True in the loss function 'linear'.  \n",
    "When you set from_logits=True, then it expects the output layer of the model to be 'linear' (logits), because the loss function calculates the softmax itself with a more numerically stable method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853978c",
   "metadata": {},
   "source": [
    "\n",
    "import tensorflow as tf    \n",
    "from tensorflow.keras.models import Sequential    \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy  \n",
    "model=Sequential()  \n",
    "model.add(Dense(25,activation='relu'))  \n",
    "model.add(Dense(10,activation='relu'))  \n",
    "model.add(Dense(10,activation='linear'))  \n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6350cc",
   "metadata": {},
   "source": [
    "Moreover, for a multiclass classfication we place in the output layer the same number of neurons as the number of target labels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c58bf9",
   "metadata": {},
   "source": [
    "## Advanced optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431bc97",
   "metadata": {},
   "source": [
    "There are better algorithms to minimize the cost function than gradient descent and allow to train the neural network in a better way. The optimizer adam algorithm adjusts the learning rate automatically. Adams stands for Adaptive moment estimation. If $w_{j}$ keeps moving in the same direction, increase $\\alpha_{j}$. If $\\alpha_{j}$  keeps oscillating, reduce $\\alpha_{j}$.      \n",
    "  model.compile(optimizer='adam',loss='categorical_crossentropy')  \n",
    "  model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a828bf",
   "metadata": {},
   "source": [
    "**Additional layer types**  \n",
    "A convolutional layer:  Each neuron only looks at part of the previous layer's inputs.  \n",
    "Multiple convolutional layers are called convolutional neural network.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bafe3",
   "metadata": {},
   "source": [
    "## Advices for applying machine learning systems - Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23c36c",
   "metadata": {},
   "source": [
    "Machine learning diagnostic: A test that you run to gain insight into what is/isnt working with a learning algorithm, to gain guidance into improving its performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258acc78",
   "metadata": {},
   "source": [
    "## Evaluating a model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20cc69ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cmuro'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c2d4d",
   "metadata": {},
   "source": [
    "In the context of machine learning, diagnotic is a test that you run to gain insight into what is/isn‚Äôt working with a learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a96b4",
   "metadata": {},
   "source": [
    "How to evaluate our model?  \n",
    "* Split the training set into two subsets: 70% training set, 30% test set. \n",
    "  \n",
    "In the train/test procedure for linear regression (for squared error cost)  \n",
    "* Fit the parameters by minimizing the cost function $J(\\vec{w},b)$  \n",
    "$$ J(\\vec{w},b)=\\left[  \\frac{1}{2_{m_{train}}} \\sum^{m_{train}}_{i=1}( f_{\\vec{w},b} (\\vec{x}^{(i)})-y^{(i)})^{2}+\\frac{\\lambda}{2m_{train}} \\sum_{j=1}^{n}w_{j}^{2}  \\right]  $$\n",
    "* Compute test error  \n",
    "$$ J_{test}(\\vec{w},b)=\\frac{1}{2m_{test}}\\left[  \\sum_{i=1}^{m_{test}}( f_{\\vec{w},b}(\\vec{x}_{test}^{(i)}) -y_{test}^{(i)})^{2} \\right] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b0144",
   "metadata": {},
   "source": [
    "In the train/test procedure for classification problem  \n",
    "* Same, split into teo subsets: training set and test set\n",
    "* Fit the parameters by minimizing the cost funciton\n",
    "$$ J(\\vec{w},b)=- \\frac{1}{m_{train}} \\sum_{i=1}^{m_{train}}[ y^{(i)}log( f_{\\vec{w},b} (\\vec{x}^{(i)}) ) -(1-y^{(i)})( log(1-f_{\\vec{w},b}(\\vec{x}^{i})))  ] +\\frac{1}{2m_{train}} \\sum_{j=1}^{n}w_{j}^{2} $$\n",
    "* Compute the test error  \n",
    "$$ J_{test}(\\vec{w},b)=- \\frac{1}{m_{test}} \\sum_{i=1}^{m_{test}}[ y_{test}^{(i)}log( f_{\\vec{w},b} (\\vec{x}_{test}^{(i)}) ) -(1-y_{test}^{(i)})( log(1-f_{\\vec{w},b}(\\vec{x}_{test}^{i})))  ] +\\frac{1}{2m_{test}} \\sum_{j=1}^{n}w_{j}^{2} $$  \n",
    "  \n",
    "When applying machine learning to classification problems, there's actually one other definition of J tests and\n",
    "J train that is maybe even more commonly used. Which is instead of using the logistic loss to compute the test error and the training error to instead measure what the fraction of the test set, and the fraction of the training set that the algorithm has misclassified.  \n",
    "\n",
    "* $J_{test}(\\vec{w},b)$ is the fraction of the test set that has been misclassified.  \n",
    "* $J_{train}(\\vec{w},b)$ is the fraction of the training set that has been misclassified.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f90113",
   "metadata": {},
   "source": [
    "**Model selection and training/cross validation/test sets**  \n",
    "* $J_{test}(\\vec{w},b)$ is better estimate of how well the model will generalize to new data compared $J_{train}(\\vec{w},b)$  \n",
    "* We use the cross validation subset to check or trust check the validity or really the accuracy of different models. We have also the cost function $J_{cv}(\\vec{w},b)$ which should be low.\n",
    "* It's considered best practice in machine learning that if you have to make decisions about your model, such as fitting parameters or choosing the model architecture, such as neural network architecture or degree of polynomial if you're fitting a linear regression, to make all those decisions only using your training set and your cross-validation set, and to not look at the test set at all while you're still making decisions regarding your learning algorithm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656acfd1",
   "metadata": {},
   "source": [
    "## Diagnosing bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d615b9",
   "metadata": {},
   "source": [
    "Looking at the variance and bias of learning algorithm gives you very good guidance at what to do next.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee088f5d",
   "metadata": {},
   "source": [
    "A more systematic way to diagnose or to find out if the algorithm has high bias or high bias is to look the performance of the algorithm on the training set.\n",
    "A characteristic Q that the algorithm has high variance will be that $J_{cv}$ is much higher than $J_{train}$. When the model is jist right $J_{train}$ and $J_{cv}$ is low. \n",
    "* High bias (under fit), $J_{train}$ will be high ($J_{train}\\sim J_{cv}$).\n",
    "* High variance (overfit) $J_{cv}>>J_{train}$ ($J_{train}$ may be low).  \n",
    "* High bias and high variance $J_{train}$ will be high and $J_{cv}>>J_{train}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030fc39",
   "metadata": {},
   "source": [
    "**Regularization and bias/variance**  \n",
    "Choose a better $\\lambda$ in regularization. Recall that $\\lambda$ is a parameter that controls how much you trade-off keeping the parameters $w_{j}$ small versus fitting the training data well.  \n",
    "* High bias, $\\lambda$ large, underfit\n",
    "* High variance, $\\lambda$ small, overfit\n",
    "  \n",
    "Cross validation helps to choose a good $\\lambda$ parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21237f7c",
   "metadata": {},
   "source": [
    "**Establishing a baseline level of performance**  \n",
    "When judging if the training error is high is often useful to establish a baseline level of performance.   \n",
    "* What is the level of error you can reasonably get to get to?\n",
    "    \n",
    "One common way to establish a baseline level performance is to measure how well:\n",
    "* Human level performance\n",
    "* Compething algorithm performance\n",
    "* Guess based on experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92828cba",
   "metadata": {},
   "source": [
    "**Learning curve**  \n",
    "They help to understand hoy your learning algorithm is doing as a function of the amount of experience whereby experencie I mean , for e.g. the number of training examples it has.  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfae36f",
   "metadata": {},
   "source": [
    "When we have a small number of training examples is relatively easy to get zero or very small training error but for a large data set is harder to fit all training examples.  \n",
    "The $J_{cv}$ error curve will be tipycally higher than the training error curve. \n",
    "* If a learning algorithm suffers from high bias, getting more training data will not help.\n",
    "* If the algororithm suffers high variance getting more training data is likely to help. The cross validation error will come down and approach to train error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45f472",
   "metadata": {},
   "source": [
    "**Deciding what to try next revisited**  \n",
    "* Try to decide if our algorithm has high bias or high variance.\n",
    "* For high bias: Try getting additional features, try adding polynomial features, try decreasing $\\lambda$.\n",
    "* For high variance: Get more training examples, try smaller sets of features, try increasing $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc2f1b",
   "metadata": {},
   "source": [
    "**Bias/Variance and neural networks**  \n",
    "* Bias-variance tradeoff.\n",
    "* Large neural networks are low bias machine\n",
    "* If it does not doing well on the training set, just use a bigger neural network; more hidden layers, or more hidden units per layer.\n",
    "* It it is doing well on the training set, then check on the cross validation set. If the answer is not, then we have high variance and we can try get more data and going back to the training set.\n",
    "* A large neural network will usually do as well or better than a smaller one so long as regularization is chose appropiately. \n",
    "* To implement regularization in tensorflow:  \n",
    "Dense(100,activation='relu',kernel_regularizer=L2(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df6c38",
   "metadata": {},
   "source": [
    "**Machine learning development process**  \n",
    "Iterative loop of ML development:  \n",
    "* Choose architecture (model,data,etc)\n",
    "* Implement a train model\n",
    "* Diagnostics (bias,variance, and error analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d420cf8d",
   "metadata": {},
   "source": [
    "**Error analysis**  \n",
    "By manually examining a set of examples that the algorithm is misclassifying or mislabeling leads to elucidate which changes to the model are more promising to try next.  \n",
    "  \n",
    "**Adding data**  \n",
    "When training machine learning algorithms, it feels like always we wish we had even more data almost all the time.  \n",
    "* Trying to add more data of all types can be slow and expensive. Instead, add more data of the types where error analysis has indicated it might help.  \n",
    "* Beyond getting brand new training examples (x,y), another technique: data augmentation.  \n",
    "* Augmentation: modifying an existing training example to create a new training example.\n",
    "* Distortion introduced should be representation of type of noise/distortions in the test set.\n",
    "* Usually does not help to add purely random/meaningless noise to your data.   \n",
    "* Data synthesis: using artificial data inputs to create a new training example.  \n",
    "* Enginner the data used by your system: Convential model-centric approach, or Data centric approach.  \n",
    "  \n",
    "**Transfer learning: using data from a different task**    \n",
    "* Use data from a different task but training the same model architecture except for the final ouput layer (in the case of neural network architecture). Only train output layers parametes, or try all the parameters.  \n",
    "* It must have the same input types.\n",
    "* You can download from internet preload trained neural networks and we just need to fine tune with our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f849240",
   "metadata": {},
   "source": [
    "**Full cycle of machine learning project**  \n",
    "* Define project, scope project\n",
    "* Define and collect data to train the machine learning system\n",
    "* Train the model, error analysis & iterative improvement\n",
    "* Deploy in production, monitor and mantain system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8c3bb",
   "metadata": {},
   "source": [
    "For deployment, some software enginering is needed.\n",
    "Emerging field:\n",
    "* MLOps, machine learning operations: It refers to the practice of how systematically build, deploy, and mantain machine learning systems "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd283db6",
   "metadata": {},
   "source": [
    "**Fairness, bias and ethics**  \n",
    "Taking into account ethics when designing a ml model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9c538",
   "metadata": {},
   "source": [
    "## Descision three model - Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e06abb5",
   "metadata": {},
   "source": [
    "Features are categorical variables. Binary classification. The structure has the form of \"trees\", where each feature is a node and in each node the algorithm takes a decision. The first node is called *root node*. The other nodes are called *decision nodes* and the final ones are *leaf nodes*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9359100",
   "metadata": {},
   "source": [
    "**Learning process**    \n",
    "* Decide what feature to use at the root node   \n",
    "* Then which feature to use next...   \n",
    "* How to choose what feature to split on at each node: Maximize purity.  \n",
    "* Decision 2: When do you stop splitting?  \n",
    "   * When a node is 100% one class  \n",
    "   * When a splitting node will result in the tree exceding a maximum depth  \n",
    "   * When improvements in purity score are below a treshold  \n",
    "   * When number of examples in a node is below a treshold  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe22d14f",
   "metadata": {},
   "source": [
    "**Measuring purity**  \n",
    "* *Entropy* as measure of impurity. Lets $p_{1}$ fraction of population 1 and $p_{0}=1-p_{1}$. More entropy more impurity.  \n",
    "The entrypy function is defined as   \n",
    "$$H(p_{1})=-p_{1}log_{2}(p_{1})-p_{0}log_{2}(p_{0}),$$\n",
    "Summarizing the entropy function is a measure of impurity of a set of data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f03ad",
   "metadata": {},
   "source": [
    "In decision tree learning, the reduction of entropy is called information gain. The entropy depends on the number of examples, so we calculate the entropy of the rot not minus the weighted average. This quantity is called the *information gain*.  \n",
    "With major information gain then bigger reduction in entropy.   \n",
    "The general formula of information gain:  \n",
    "$$ IG=H(p_{1}^{root})-\\left( w^{left}H(p_{1}^{left})+w^{right}H(p_{1}^{right})  \\right).  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55d0c0",
   "metadata": {},
   "source": [
    "**Putting it together**  \n",
    "* Start with all the learning examples at the root node\n",
    "* Calculate information gain for all possible features, and pick the one with the highest information gain\n",
    "* Split dataset according the selected feature and create left and right branches of the tree\n",
    "* Keeping repeating the splitting process until stopping criteria is met:\n",
    "   * When a node is 100% one class\n",
    "   * When splitting a node will result in the tree exceeding a maximum depth\n",
    "   * Information gain from additional splits is less than treshold\n",
    "   * When number of examples in a node is below a treshold  \n",
    "   \n",
    "The bigger the maximum depth the bigger the decision tree could cause overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c2749",
   "metadata": {},
   "source": [
    "**Using one-hot encoding of categorical features**  \n",
    "What if we have features that can have more of two discrete values? let us say $n$ values.  \n",
    "one hot encoding: We create $k$ binary features (0 or 1 valued)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b17c1",
   "metadata": {},
   "source": [
    "**Continuous valued features**  \n",
    "Split into continuous features: Consider many different values for a treshold and take the one that results in the best information gain.  \n",
    "  \n",
    "**Regression trees**  \n",
    "Instead of reducing the impurity we reduce the variance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9514ba5",
   "metadata": {},
   "source": [
    "### Tree ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f1e08",
   "metadata": {},
   "source": [
    "One single-tree is very sensitive to changes of the data. One solution is to build a lot of decision trees. The we get them to vote, and the majority votes of the predictions. it makes the algorithm more robust.   \n",
    "  \n",
    "**Random forest algorithm**  \n",
    "It is a tree ensemble algorithm.  \n",
    "Given training set of size $m$  \n",
    "For $b=1$ to $B$:  \n",
    "   Use sampling with remplacement to create a new training set of size $m$\n",
    "   Train a decision tree on the new dataset\n",
    "   \n",
    "The number $B$ is around 100, people recommend any value from 64 to 200. $B$ stands for bag.  \n",
    "  \n",
    "Randomizing the feature choice: ath each node, when choosing a feature to use to split, if $n$ features are available, pick a random subset of $k<n$ features and allow the algorithm to only choose from that subset of features. $k=\\sqrt{n}$.  \n",
    "  \n",
    "**XGBoost**  \n",
    "Today by far the most commonly used way or implementation of decision tree ensembles or decision trees there's an album called XGBoost. It runs quickly, the open source implementations are easily used, has also been used very successfully to win many machine learning competitions as well as in many commercial applications. \n",
    "Given training set of size $m$  \n",
    "For $b=1$ to $B$:  \n",
    "   Use sampling with remplacement to create a new training set of size $m$. But instead of picking from all examples with equal (1/m) probability, make it more likely to pick missclassified examples from previous trained trees.     \n",
    "   Train a decision tree on the new dataset  \n",
    "  \n",
    "Classification:  \n",
    "from xgboost import XGBClassifier  \n",
    "model=XGBClassifier()  \n",
    "model.fit(X_train,y_train)    \n",
    "y_pred=model.predict(X_test)    \n",
    "   \n",
    "Regression:    \n",
    "from xgboost import XGBRegressor  \n",
    "model=XGBRegressor()  \n",
    "model.fit(X_train,y_train)  \n",
    "y_pred=model.predict(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4f262",
   "metadata": {},
   "source": [
    "### When to use decision trees  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e65cf",
   "metadata": {},
   "source": [
    "**Decision trees vs Neural Networks**  \n",
    "Decision trees and tree ensembles:  \n",
    "* Works well on structured data  \n",
    "* Not recommended for unestructured data (images, audio)  \n",
    "* Fast\n",
    "* Small trees may be human interpretable  \n",
    "* If you decide to use decision trees or tree ensembles use XGBOOST for most of the applications   \n",
    "   \n",
    "    \n",
    "Neural networks: \n",
    "* Works well on all types of data, incluiding tabular (structured) and unstructured data.  \n",
    "* May be slower than decision tree\n",
    "* Works with transfer learning\n",
    "* When building a system of system of multiple models working together, it might be easier to string together multiple neural networks.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b5fc7",
   "metadata": {},
   "source": [
    "# Unsupervised Learning, Recommenders, Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f79f51",
   "metadata": {},
   "source": [
    "## Unsupervised learning - Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5ef98c",
   "metadata": {},
   "source": [
    "**Clustering algorithm**    \n",
    "A clustering algortihm looks at the number of data points and automatically finds data points that are related or similar to each other. We don't have labeled data, and ask to algorithm to find the structure of the data.  \n",
    "  \n",
    "**K-means intuition**  \n",
    "- It takes a random guess at where might be the center of the clusters that you might ask to find. Randomly take the points at where might be the centers of the different clusters\n",
    "- The algorithm repeat two different hings:\n",
    "   - Assign points to *cluster centroids*\n",
    "   - Move cluster centroids\n",
    "- Assign each point of the data to its closest centroid\n",
    "- Recompute the centroids  \n",
    "  \n",
    "**K-means algorithm**  \n",
    "* Randomly initialized K cluster centroids $\\mu_{1},\\mu_{2},\\dots,\\mu_{k}$  \n",
    "* Repeat :\n",
    " - Assign points to cluster centroids\n",
    "  for $i=1,\\dots,m$  \n",
    "  $c^{(i)}:=$ index from (1 to $K$) of cluster centroid closest to $x^{(i)}$  \n",
    "  $min_{k}||x^{(i)}-\\mu_{k}||^{2}$\n",
    " - Move cluster centroids \n",
    "  for i=1,$\\dots$ K  \n",
    "  $\\mu_{k}$ average of points assigned to cluster k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f716dc",
   "metadata": {},
   "source": [
    "**Optimization objective**  \n",
    "Also optimizing a specific cost function:  \n",
    "$c^{(i)}$ index of cluster $(1,2,\\dots,K)$ to which example $x^{(i)}$ is currently assigned.  \n",
    "$\\mu_{k}$ = cluster centroid $k$.  \n",
    "$\\mu_{c^{(i)}}$ = cluster centroid of cluster to which example $x^{(i)}$ has been assigned. \n",
    "  \n",
    "The cost function or also called the distortion function:    \n",
    "$$J(c^{(1)},\\dots,c^{(m)},\\mu_{1},\\dots,\\mu_{k})=\\frac{1}{m}\\sum_{i=1}^{m}||x^{(i)}-\\mu_{c^{(i)}}||^{2}.$$\n",
    "* Repeat :\n",
    " - Assign points to cluster centroids\n",
    "  for $i=1,\\dots,m$  \n",
    "  $c^{(i)}:=$ index from (1 to $K$) of cluster centroid closest to $x^(i)$  \n",
    "  $min_{k}||x^{(i)}-\\mu_{k}||^{2}$\n",
    " - Move cluster centroids \n",
    "  for i=1,$\\dots$ K  \n",
    "  $\\mu_{k}$ average of points assigned to cluster k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d586774d",
   "metadata": {},
   "source": [
    "**Initializing K-means**  \n",
    "The very first step of K-means algorithm is to choose random locations as the initial guesses for cluster centroids $\\mu_{1},\\dots,\\mu_{k}$.  \n",
    "Random initialization:  \n",
    "- Choose $k<m$  \n",
    "for $i=1$ to 100:\n",
    "- Randomly pick $K$ training examples\n",
    "- Run K- means. Get $c^{(1)},\\dots,c^{(m)}$ ,$\\mu_{1},\\dots,\\mu_{k}$ equal to those $K$ examples. Computer cost function  \n",
    "$J(c^{(1)},\\dots,c^{(m)},\\mu_{1},\\dots,\\mu_{k})$\n",
    "- Pick the set of clusters that gave lowest cost $J$  \n",
    "  \n",
    "**Choosing the number of clusters**  \n",
    "- The elbow method: We run $K$ means with a variety of values of $K$ and plot the cost function as the number of clusters. Andrew does not use this method because in a lot of application the right $K$ is often ambiguos.  \n",
    "- Often, you want to get clusters for some later downstream purpose\n",
    "- Evaluate $K-$means based on how well it performs on the later purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e4534",
   "metadata": {},
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68ac64",
   "metadata": {},
   "source": [
    "Anomaly detection algorithms look at unlabeled dataset of normal events and thereby learns to detect or to raise a red flag for if there is an unusual events.  \n",
    "The most common way to carry out anomaly detection is through a technique called desnsity estimation.  \n",
    "If you have a dataset ${x^{1},x^{2},\\cdots,x^{m}}$. The first thing is build a model for porbability $p(x)$ of $x$. the for a new $x_{test}$, we compute the probability $p(x_{x})$ and if it is small, i.e. $p(x_{test})<\\epsilon$ with $\\epsilon$ a small number, we will raise a flag that this could be an anomaly.  \n",
    "Anomaly detection is used in fraud detection, manufacturing.  \n",
    "  \n",
    "In order to apply anomaly detection, we use the normal distribution. Probability of $x$ is determined by a Gaussian with mean $\\mu$ and variance $\\sigma^{2}$.    \n",
    "$$p(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{ \\frac{-(x-\\mu)^{2}}{2\\sigma^{2}}  } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dbcff",
   "metadata": {},
   "source": [
    "Maximum likelihood for $\\mu$ and $\\sigma$:  \n",
    "$$ \\mu=\\frac{1}{m}\\sum_{i=1}^{m}x^{(i)}, \\quad \\sigma^{2}=\\frac{1}{m}\\sum_{i=1}^{m}(x^{(i)}-\\mu)^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18a248",
   "metadata": {},
   "source": [
    "**Anomaly detection algorithm: Density estimation**   \n",
    "Training set: $\\{\\vec{x}^{1},\\vec{x}^{2},\\cdots,\\vec{x}^{m}\\}$. Each example $\\vec{x}^{i}$ has $n$ features. It is a vector $\\vec{x}=(x_{1},\\cdots,x_{n})$.  \n",
    "$$p(\\vec{x})=p(x_{1};\\mu_{1},\\sigma_{1}^{2})*p(x_{2};\\mu_{2},\\sigma_{2}^{2})*\\cdots* p(x_{n};\\mu_{n},\\sigma_{n}^{2})=\\Pi_{j=1}^{n}p(x_{j};\\mu_{j},\\sigma_{j}^{2}) $$  \n",
    "   \n",
    "1. Choose n features $x_{1}$ that you think might be indicative of anomalous examples.\n",
    "2. Fit parameters: $\\mu_{1},\\cdots,\\mu_{n},\\sigma_{1}^{2},\\cdots,\\sigma_{n}^{2}$.\n",
    "3. Given a new example $x$, compute $p(x)$.   \n",
    "4. Anomaly if $p(x)<\\epsilon$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd768ad",
   "metadata": {},
   "source": [
    "**Developing and evaluating an anomaly detection system**  \n",
    "When developing a learning algorithm is much easier if we have a way of evaluating our learning algorithm. \n",
    "  \n",
    "Assume we have labeled data, of anomalous and non-anomalous examples.  \n",
    "  \n",
    "1. Fit model $p(x)$ on training set $x^{(1)},x^{(2)},\\cdots,x^{(m)}$\n",
    "2. On a cross validation/test example $x$, predict. If $p(x)< \\epsilon$ (anomaly), if $p(x) \\geq \\epsilon$ normal.\n",
    "  \n",
    "Alternative: No test set  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b0ce4",
   "metadata": {},
   "source": [
    "**Anomaly detection vs supervised learning**  \n",
    "Anomaly detection:  \n",
    "- Very small number of positive examples ($y=1$). (0-20 is common)  \n",
    "- Large number of negative (y=0) examples.  \n",
    "- Many different \"types\" of anomalies. Hard for any allgorithm to learn from positive examples what anomalies look like; future animalies may look nothing like any of the anomalous examples we have seen so far.  \n",
    "  \n",
    "Supervised learning:  \n",
    "- Large number of positive negative examples.  \n",
    "- Enough positive examples for algorithm to get sense of whta positive examples are like, future positive examples likely to be similar to one in training set. \n",
    "  \n",
    "**Choosing what features to use**    \n",
    "Choosing a good choice of features out to be really important. tune the features for anomaly detection.    \n",
    "Try to make sure the features you give it are more or less Gaussian. Plot the histogram of the feature. Transform the feature to have a more Gaussian $np.log(x)$. $x\\rightarrow log(x+C)$  \n",
    "  \n",
    "**Error analysis for anomaly detection**  \n",
    "We want $p(x)$ large for normal examples of $x$ and small for anomalous examples.   \n",
    "The most common problem:  \n",
    "$p(x)$ is comparable for nomal and anomalous examples; it is large for both.  \n",
    "  \n",
    "The process:  \n",
    "- Train the model and see what anomalies in the cross validation set the algortihm is failing to detect.\n",
    "- Then to look at those examples to see if that can inspire the creation of new features that would allow the algorithm to spot. That example takes on unusually large or unusually small values on the new features, so that you can now successfully flag those examples as anomalies. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b3a4f",
   "metadata": {},
   "source": [
    "## Recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df6d10",
   "metadata": {},
   "source": [
    "In usual recommender systems, you have some number of users $n_{u}$ as well some number of items $n_{m}$ that you want to recommend to the users. $r(i,j)=1$ if user $j$ has rated movie $i$. $y^{(i,j)}=$ rating given by user $j$ to movie $i$ (defined only if $r(i,j)=1$).  \n",
    "  \n",
    "**Using per-item features**  \n",
    "We have a number $n$ of features.  \n",
    "For user j: Predict user j's rating for movie j as $w^{(j)}\\cdot x^{(i)}+b^{(j)}$. Then  \n",
    "$w^{(j)},b^{(j)}=$ parameters for user $j$  \n",
    "$x^{(i)}=$ feature vector for movie $i$\n",
    "  \n",
    "For user $j$ and movie $i$, predict rating: $w^{(j)}\\cdot x^{(i)}+b^{(j)}$  \n",
    "$m^{(j)}=$ no. of movies rated by user $j$  \n",
    "To learn $w^{(j)},b^{(j)}$.  \n",
    "  \n",
    "Let us focus on one user $j$. The cost function to minimize is \n",
    "$$J(w^{(j)},b^{(j)})= \\frac{1}{2m^{(j)}} \\sum_{i:r(i,j)=1}(w^{(j)}\\cdot x^{(i)}+ b^{(j)}-y^{(i,j)^{2}} )+\\frac{\\lambda}{2m^{(j)}} \\sum_{k=1}^{n}(w_{k}^{(j)})^{2}  $$  \n",
    "It is convenient to eliminate the constant $m^{(j)}$.  \n",
    "The goal of a collaborative filtering recommender system is to generate two vectors: For each user, a 'parameter vector' that embodies the movie tastes of a user. For each movie, a feature vector of the same size which embodies some description of the movie. The dot product of the two vectors plus the bias term should produce an estimate of the rating the user might give to that movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef737ffc",
   "metadata": {},
   "source": [
    "**Collaborative filtering algorithm**  \n",
    "How to learn if we don't have features and we have to learn them from the data. Suposse we have the parameters $w^{(j)},b^{(j)}$ for $n_{u}$ users to learn $x^{(i)}$:  \n",
    "$$ J(x^{(i)})=\\frac{1}{2}\\sum_{j:r(i,j)=1}(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)})^{2} +\\frac{\\lambda}{2} \\sum_{k=1}^{n}(x_{k}^{(i)})^{2} $$\n",
    "  \n",
    "To learn $x^{(1)},\\dots, x^{n_{m}}$:  \n",
    "$$ \\frac{min}{x^{(1)},\\cdots,x^{n_{m}}} J(x^{(1)},\\dots, x^{n_{m}}) = \\frac{1}{2} \\sum_{i=1}^{n_{m}} \\sum_{j:r(i,j)=1}(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)})^{2}+\\frac{\\lambda}{2}  \\sum_{i=1}^{n_{m}}\\sum_{k=1}^{n}(x_{k}^{(i)})^{2}$$\n",
    "i.e. we minimize $x^{(1)},\\dots, x^{n_{m}}$, instead of minimizing  $w^{(1)},\\dots, w^{n_{u}},b^{(n_{u})}$ as in the case of learning these parameters. By putting them together both minimization process \n",
    "  $$  J(w,b,x)=\\frac{1}{2}\\sum_{(i,j):r(i,j)=1} (w^{(j)}\\cdot x^{(i)} + b^{(j)} -y^{(i,j)}) + \\frac{\\lambda}{2}\\sum_{j=1}^{n_{u}}\\sum_{k=1}^{n}(w_{k}^{(j)})^{2}+\\frac{\\lambda}{2}\\sum_{j=1}^{n_{m}}\\sum_{k=1}^{n}(x_{k}^{(i)})^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416f324",
   "metadata": {},
   "source": [
    "Then, the gradient descent algorithm takes the form\n",
    "repeat {\n",
    "$$  w^{(j)}_{i}=w^{(j)}_{i}-\\alpha \\frac{\\partial}{\\partial w^{(j)}_{i}} J(\\vec{w},b)  $$  \n",
    "$$ b^{(j)}=b^{(j)}-\\alpha \\frac{ \\partial }{\\partial b^{(j)}} J(\\vec{w},b)  $$ \n",
    "$$ x^{(i)}_{k}=x^{(i)}_{k}-\\alpha \\frac{\\partial}{\\partial x^{(i)}_{k}}J(w,b,x) $$} i.e. the parameters are $w,b,x$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77061cfb",
   "metadata": {},
   "source": [
    "**Binary labels: favs, likes and clicks**  \n",
    "Previously: Predict $y^{(i,j)}$ as $w^{(j)}\\cdot x^{(i)}+b^{(j)}$  \n",
    "For binary lables, predict the porbability of $y^{(i,j)}=1$ is given by $g(w^{(j)}\\cdot x^{(i)}+b^{(j)})$ where $g(z)=\\frac{1}{1+e^{-z}}$.   \n",
    "  \n",
    "The loss for binary labels: $y^{(i,j)}:\\quad f_{(w,b,x)}(x)= g(w^{(j)}\\cdot x^{(i)}+b^{(j)})$.  \n",
    "The binary loss function for a single example:  \n",
    "$$ L(f_{(w,x,b)}(x),y^{(i,j)})=-y^{(i,j)}log(f_{(w,b,x)}(x))-(1-y^{(i,j)})log(1-f_{w,b,x}(x)) $$\n",
    "Then, the cost function for collaborative filtering:  \n",
    "$$  J(w,x,b)=\\sum_{(i,j):r(i,j)}L(f_{(w,b,x)}(x),y^{(i,j)}).  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be15066",
   "metadata": {},
   "source": [
    "### Recommender systems implementation detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51d46c",
   "metadata": {},
   "source": [
    "**Mean normalization**  \n",
    "The algorithm could run better with mean normalization. In the case of the movies, if we normalize the movie ratings to have a consistent average value.  \n",
    "We take as a matrix the values of the ratings of the users. In each row (each movies) compute the average rating that was given. Then we create the vector $\\mu$ with the means. We take the original matrix and substract from every rating the mean rating that it was given. Using this matrix with $y^{(i,j)}$, we can learn $w^{(j)},b^{(j)},x^{(j)}$. For user $j$, on movie $i$ predict: $w^{(j)}\\cdot x^{(i)}+b^{(j)}+\\mu_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7fe1d",
   "metadata": {},
   "source": [
    "### Tensorflow implementation of collaborative filtering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5807b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom training loop\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92527b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2130464582.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [4]\u001b[1;36m\u001b[0m\n\u001b[1;33m    from i in range(iterations):\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Overview of the program\n",
    "w=tf.Variable(3.0)\n",
    "x=1.0\n",
    "y=1.0\n",
    "alpha=0.01\n",
    "iterations=30\n",
    "from iter in range(iterations):\n",
    "    # Use Tensroflow's Gradient tape to record the steps\n",
    "    # used to compute the cost J, to enable auto differentation\n",
    "    with tf.GradientTape() as tape:\n",
    "        fwb=w*b\n",
    "        costJ=(fwb-y)**2\n",
    "    \n",
    "    # Use the gradient tape to calculate the gradient\n",
    "    # of the cost with respect to the parameter w\n",
    "    [dJdw] = tape.gradient(costJ,[w])\n",
    "    \n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of w to reduce the cost\n",
    "    w.assign(-alpha*dJdw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8a814",
   "metadata": {},
   "source": [
    "**Finding related items**  \n",
    "Collaborative filtering algorithm gives you a nice way to find related items.  \n",
    "The features $x^{(i)}$ of item $i$ are quite hard to interpret, but collectively these features do convey something about what that movie is like. It turns out that given features $x^{(i)}$ of item $i$ we can try to find the item $k$ with $x^{(k)}$ similar to $x^{(i)}$. In particular, given a feature vector $x^{(k)}$, the way we determine what are known as with the samllest distance\n",
    "$$ \\sum_{l=1}^{n}(x_{l}^{(k)}-x_{l}^{(i)})^{2}  $$  \n",
    "   \n",
    "Limitations of collaborative filtering: \n",
    "* It is not vey good at the cold start problem. How rank new items that few users have rated? How to show something reasonable to new users who have rated few items?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36beecb",
   "metadata": {},
   "source": [
    "### Content-based filtering  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01677035",
   "metadata": {},
   "source": [
    "**Collaborative filtering vs Content-based filtering**  \n",
    "  \n",
    "- Collaborative filtering: Recommend items to you based on ratings of users who gave similar ratings as you.  \n",
    "- Content based filtering: Recommend items to you based on features of user and item to find good match.  \n",
    "  \n",
    " Some user features $x_{\\mu}^{(j)}$ for user $j$: Age, Gender, Country, Movies watched, Average rating per genre.  \n",
    "   \n",
    " Movie features $x_{m}^{(i)}$ for movie $i$: Year, Genres, Reviews, Average rating.  \n",
    "   \n",
    " These vectors usually have different sizes.  Learning to match user and movies. Predict rating of user $j$ on movie $i$ as:  \n",
    " $$ v_{u}^{(j)}\\cdot v_{m}^{(i)} $$  \n",
    " where $v_{u}^{(j)}$ is computed from $x_{u}^{(j)}$, and $v_{m}^{(i)}$ from $x_{m}^{(i)}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a64659",
   "metadata": {},
   "source": [
    "**Deep learning for content based filtering**  \n",
    "We have the user and feature networks from which we obtain $v_{u}$ and $v_{m}$, and $g(v_{u}^{(j)}\\cdot v_{m}^{(i)})$ to predict the probabilti that $y^{(i,j)}$ is 1.  \n",
    "We can combine both neural networks to make the prediciton. The cost function  \n",
    "$$ J=\\sum_{(i,j):r(i,j)=1}(v_{u}^{(j)}\\cdot v_{m}^{(i)}-y^{(i,j)})^{2}+NN \\quad regularization\\quad term  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849693b",
   "metadata": {},
   "source": [
    "To find movies similar to movie $i$: $|| v_{m}^{(k)}-v_{m}^{(i)} ||^{2}$ is small.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1fe6f3",
   "metadata": {},
   "source": [
    "**Recommending from a large catalogue**  \n",
    "Two steps: Retrieval and Ranking steps.  \n",
    "Retrieval:  \n",
    "* Generate large list of plausible item candidates\n",
    "* Combine retrieved items into list, removing duplicates and items already watched  \n",
    "  \n",
    "Retrieving more items results in better perfomance, but slower recommendations. To analyse/optimize the trade-off, carry out offline experiments to see if retrieving additional items results in more relevant reccommendations (i.e., $p(y^{(i,j)})$=1  of items displayed to user are higher )   \n",
    "      \n",
    "Ranking:  \n",
    "* Take list retrieved and rank using learned model\n",
    "* Display ranked items to user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412ce79",
   "metadata": {},
   "source": [
    "**Tensorflow Implementation**  \n",
    "We have to define both networks for the user and the items. Recall that both needs to have the sampe number of neurons at the output. The genral syntax takes the form:  \n",
    "user_NN=tf.keras.models.Sequential([tf.keras.layers.Dense(256,activation='relu'),  \n",
    "tf.keras.layers.Dense(128,activation='relu'),  \n",
    "tf.keras.layers.Dense(32)])  \n",
    "  \n",
    "item_NN=tf.keras.models.Sequential([  \n",
    "tf.keras.layers.Dense(256,activation='relu'),  \n",
    "tf.keras.layers.Dense(128,activation='relu'),  \n",
    "tf.keras.layers.Dense(32)  \n",
    "])    \n",
    "  \n",
    "% Create the user input and point to the base network\n",
    "input_user.tf.keras.layers.Input(shape=(num_user_features))  \n",
    "vu=user_NN(input_user)  \n",
    "vu=tf.linalg.12_normalize(vu,axis=1)  \n",
    "  \n",
    "% Create the item input and point to the base netwrok\n",
    "input_item=tf.keras.layers.Input(shape=(num_item_features))  \n",
    "vm=item_NN(input_item)  \n",
    "vm=tf.linalg.12_normalize(vm,axis=1)  \n",
    "  \n",
    "% measure the similarity of the tow vector outputs  \n",
    "output=tf.keras.layers.Dot(axes=1)([vu,vm])  \n",
    "  \n",
    "% specify the inputs and output of the model    \n",
    "model=Model([input_user,input_item],output)  \n",
    "  \n",
    "% specify the cost function \n",
    "cost_fn=tf.keras.losses.MeanSquaredError()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b6c9e",
   "metadata": {},
   "source": [
    "## Week 3 - Reinforcement learning   \n",
    "We have the state $s$. the task is to find a function that maps from the state $s$ to an action $a$. Using a neural netwrok using supervised learning to directly learn the mapping from the states $x$ to an action $y$.  \n",
    "  \n",
    "A key input in reinforcement learning is something called the *reward   function* which tells when it is doing well or bad, i.e. positive reward or negative reward.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba142f",
   "metadata": {},
   "source": [
    "**The return in reinforcement learning**  \n",
    "The action through different states. How do you know if a particular kind of rewards is better or work than different set of rewards.  \n",
    "The return is the sum of the rewards but wighted by one additional factor which is called discount factor which is a number a little bit less than 1.  \n",
    "$$Return=R_{1}+\\gamma R_{2}+\\gamma^{2}R_{3}+\\dots$$  \n",
    "what the *discount factor* $\\gamma$ does it has the effect of the reinforcement learning algorithm a little bit impatient. The return depends on the actions you take."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638862c",
   "metadata": {},
   "source": [
    "In reinforcement learning, our goal is to come up with a function which is called a *policy* $\\pi$. It is a function $\\pi(s)=a$  that tells you what action to take in every state $s$ so as to maximize the return.    \n",
    "**Markov decision process** The term Markov in the MDP or\n",
    "Markov decision process refers to that the future only depends on the current state and not on anything\n",
    "that might have occurred prior to getting to the current state. In other words, in a Markov decision process,\n",
    "the future depends only on where you are now, not on how you got here. One other way to think of the Markov decision process formalism is that we have a robot or some other agent that we wish to control and what we get to do is choose actions a and based on those actions, something will happen in the world or in the environment, such as our position in the world changes or we get to sample a piece of rock and execute the science mission. The way we choose the action a is with a policy Pi and based on what happens in the world, we then get to see or we observe back what state we're in, as well as what rewards are that we get. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282453b",
   "metadata": {},
   "source": [
    "**State-action value function (Q-function) definition**  \n",
    "It is denoted by the letter Q, and it is a function of state as well as the action you want to take in that state.  \n",
    "$$ Q(s,a)= return $$  \n",
    "if you start in the state $s$, and take the action $a$ once, then behave optimally after that.  \n",
    "Picking actions from the states and take the largest value of Qfs. The best possible action in the state $s$ is the action $a$ that gives $max_{a} Q(s,a)$.      \n",
    "Computing $Q(s,a)$ is an important part of the reinforcement learning algorithm.  \n",
    "  \n",
    "**Bellman equations**  \n",
    "How you can compute these values $Q(s,a)$?. The Bellman equation helps us.  \n",
    "$s$ the current state, $R(s)$ the reward of the current state. $a$ is the current action. $s'$ the state you get after taking action $a$. $a'$ action that you take in $s'$. the Bellman equation is  \n",
    "$$Q(s,a)=R(s)+\\gamma_{max_{a'}}Q(s',a')$$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb0a08",
   "metadata": {},
   "source": [
    "#### Continuous state spaces  \n",
    "The vector state $s=[x,y,\\theta,\\dot{x},\\dot(y),\\dot{\\theta}]$ and they can take any value within is valid range.  \n",
    "We are going to train a neural network to compute or to approximate the state action value function Q(s,a) and that in turn will let us pick good actions.  \n",
    "The inputs of the neural network is the current state and current action and computes or approximate $Q(s,a)$.  \n",
    "In a state $s$, use a neural network to compute $Q(s,nothing)$, $Q(s,left)$, $Q(s,main)$, $Q(s,right)$. Pick the action tha maximizes $Q(s,a)$. \n",
    "Recall that $Q(s,a)=R(s)+\\gamma max_{a'}Q(s',a')$.  \n",
    "The input data can takes the form $x^{(1)}=(s^{(1)},a^{(1)})$ with the output $y^{(1)}$. Then $y^{(1)}=R(s^{(1)})+\\gamma max_{a'}Q(s^{'(1)},a').$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699195d3",
   "metadata": {},
   "source": [
    "Learning algorithm:  \n",
    "Initialize neural network randomly as guess of $Q(s,a)$.\n",
    "Repeat{Take actions in the lunar lander. Get $(s,a,R(s),s')$. Store 10,000 most recent ($s,a,R(s),s'$) tuples}.  \n",
    "  \n",
    "Train neural network:  \n",
    "Create a training set of 10,000 examples using  \n",
    "$$x=(s,a)\\quad y=R(s)+\\gamma max_{a'}Q(s',a') $$  \n",
    "Train $Q_{new}$ such that $Q_{new}(s,a)\\sim y$.  \n",
    "  \n",
    "It turns out that there's a change to neural network architecture that make this algorithm much more efficient. Instead, it turns out to be more efficient\n",
    "to train a single neural network to output all four (in the case of the luna lander) of these values simultaneously.  Now the output unit has four output units, and the job of the neural network is to have the four output units output Q of s, nothing, Q of s, left, Q of s, main, and q of s, right. The job of the neural network is to compute simultaneously the Q value for all four possible actions for when we are in the state s. This turns out to be more efficient because given the state s we can run inference just once and get all four of these values, and then very quickly pick the action a that maximizes Q(s,a).       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d710a",
   "metadata": {},
   "source": [
    "**Algorithm refinement: $\\epsilon$-greedy policy**  \n",
    "How to choose action while still learning?  \n",
    "In some state $s$:  \n",
    "Option 1: \n",
    "  Pick the action $a$ that maximizes $Q(s,a)$.  \n",
    "Option 2: \n",
    "  With probability 0.95, pick the action a that maximizes $Q(s,a)$. Greedy action or Explotation step.\n",
    "  With probability 0.05, pick and action $a$ randomly. \"Exploration\".  \n",
    "$\\epsilon-greedy$ policy ($\\epsilon=0.05$).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dbe569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
